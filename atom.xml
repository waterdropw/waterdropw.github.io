<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>waterdropw&#39;s blog</title>
  
  <subtitle>思绪如风，偶尔在此停留</subtitle>
  <link href="https://waterdropw.github.io/atom.xml" rel="self"/>
  
  <link href="https://waterdropw.github.io/"/>
  <updated>2025-11-20T11:50:34.446Z</updated>
  <id>https://waterdropw.github.io/</id>
  
  <author>
    <name>waterdrop wei</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>极简`Transformer`实现(基于`llama2.c`commit-4e23ad 23&#39;7/27)</title>
    <link href="https://waterdropw.github.io/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-4e23ad8/"/>
    <id>https://waterdropw.github.io/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-4e23ad8/</id>
    <published>2024-04-17T02:34:26.000Z</published>
    <updated>2025-11-20T11:50:34.446Z</updated>
    
    <content type="html"><![CDATA[<p>基于源码调试过程，以及如下两篇文章整理。</p><blockquote><p>This repo is line by line walk through of the inference file in llama2.c. Its very verbose &amp; intended for beginners.<br>You will need some familiarity with transformers architecture. If you are a complete novice refer to this excellent blog first.</p><footer><strong>RahulSChand</strong><cite><a href="https://github.com/RahulSChand/llama2.c-for-dummies">cllama2.c-for-dummies</a></cite></footer></blockquote><blockquote><p>The Illustrated Transformer。</p><footer><strong>jalammar</strong><cite><a href="https://jalammar.github.io/illustrated-transformer">illustrated-transformer</a></cite></footer></blockquote><p>llama2.c 包含了训练代码和推理实现，作者提供了如下几个预训练模型，可以直接运行 run 这个demo程序生成一个简短的小故事。</p><table><thead><tr><th>model</th><th>dim</th><th>n_layers</th><th>n_heads</th><th>n_kv_heads</th><th>max context length</th><th>parameters</th><th>val loss</th><th>download</th></tr></thead><tbody><tr><td>260K</td><td>64</td><td>5</td><td>8</td><td>4</td><td>512</td><td>260K</td><td>1.297</td><td><a href="https://huggingface.co/karpathy/tinyllamas/tree/main/stories260K">https://huggingface.co/karpathy/tinyllamas/tree/main/stories260K</a></td></tr><tr><td>OG</td><td>288</td><td>6</td><td>6</td><td>6</td><td>256</td><td>15M</td><td>1.072</td><td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin">https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin</a></td></tr><tr><td>42M</td><td>512</td><td>8</td><td>8</td><td>8</td><td>1024</td><td>42M</td><td>0.847</td><td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin">https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin</a></td></tr><tr><td>110M</td><td>768</td><td>12</td><td>12</td><td>12</td><td>1024</td><td>110M</td><td>0.760</td><td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin">https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin</a></td></tr></tbody></table><p>与一般的问答式文本生成不一样, <code>run</code> 的实现做了简化，首先是没有prompt 输入而是每次运行直接生成一个tiny story，所以也就没有针对prompt 做embedding 的 init_prefill 计算阶段，而只有 generate；其次是在生成的迭代过程中，主要的transformer计算输入输出只需要词元的 <code>token</code> 因此预先把所有词元的embedding存储在<code>token_embedding_table</code> 中，迭代过程中直接从里面读取当前位置的 embedding 参与计算，推理过程中可以省掉输入词元的embedding计算过程。</p><p>涉及到的输入文件有模型checkpoint如 <code>stories15M.bin</code> ，以及tokenizer 文件 <code>tokenizer.bin</code> ，具体的文件结构可以参考文末的分析。</p><span id="more"></span><h1 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h1><p><code>main</code>处理命令行参数，模型推理主要在<code>transformer</code>函数里面。</p><h2 id="main-执行流程"><a href="#main-执行流程" class="headerlink" title="main 执行流程"></a><code>main</code> 执行流程</h2><ol><li>解析命令行参数，包括 checkpoint 文件路径, temperature, steps</li><li>加载checkpoint 文件内容，包括模型配置和权重</li><li>加载 <code>tokenizer.bin</code></li><li>初始化运行时变量，包括kv cache等</li><li>根据给定的 seq_len (steps) 执行循环，以 BOS 作为第一个token开始：<ol><li><p>transformer 输出下一个token的logits</p></li><li><p>参考temperature的值，由logits得到token值</p><ol><li>如果temperature&#x3D;&#x3D;0，采用贪心搜索直接取最大值，$next&#x3D;argmax(logits)$</li><li>否则，随机采样得到token，$next&#x3D;sample(softmax(logits&#x2F;temperature))$ <img src="/images/llama2/classifier.png" class=""></li></ol></li><li><p>token即为vocab的index，从tokenizer中得到对应的单词并打印</p></li></ol></li><li>内存清理并退出</li></ol><h2 id="transformer执行流程"><a href="#transformer执行流程" class="headerlink" title="transformer执行流程"></a><code>transformer</code>执行流程</h2><img src="/images/llama2/tranformer_arch.png" class="" width="434" height="460"><blockquote><p>注意：因为是纯推理，所以实现的是decoder部分，att计算的是 <code>Masked Multi-Head Attention</code> ，也就是代码中的 <code>[0, pos]</code> 相当于是mask之后的。</p></blockquote><p>计算过程：</p><ol><li>从 <code>token_embedding_table</code> 中取出当前token的embedding (dim, ) 放入 <code>s-&gt;x</code> 中</li><li>循环遍历每一层：<ol><li><p>对<code>s-&gt;x</code>计算rmsnorm并存入 <code>s-&gt;xb</code></p></li><li><p>对 <code>s-&gt;xb</code> 计算 Q、K、V，结果存入 <code>s-&gt;q</code>, <code>s-&gt;k</code>, <code>s-&gt;v</code></p></li><li><p>对每个多头，计算RoPE编码的Q、K，结果存入 <code>s-&gt;q</code>, <code>s-&gt;k</code></p></li><li><p>保存当前位置的KV到缓存 <code>s-&gt;key_cache</code> , <code>s-&gt;value_cache</code> 注意K是带位置编码信息的，而V不带</p></li><li><p>kv cache (layer, seq_len, dim)，则<code>int loff = l * p-&gt;seq_len * dim</code> 是第 <code>l</code> 层的kv cache起始位置</p></li><li><p>计算多头注意力，循环遍历每个头</p><ol><li>Q起始位置，Q(dim, 1)拆分多头后维度为(n_heads, head_dim)，所以第 <code>h</code> 头的起始位置为**<code>float* q = s-&gt;q + h * head_size</code></li><li>atten score (n_heads, seq_len)，因为是按头维度存放的，所以在第  <code>h</code> 头的起始位置就是 <code>s-&gt;att + h * p-&gt;seq_len</code></li><li>kv cache在 <code>dim</code>维度拆分多头后为(layer, seq_len, n_heads, head_dim)，则第 <code>h</code> 头的偏移为 <code>h*head_size</code></li><li>计算该词元对<strong>它之前所有</strong>词元的注意力分数（包含自己），其实就是masked attention，<code>for t in 0..pos+1</code>:<ul><li>第 <code>t</code> 个词元对应在第 <code>h</code> 头内的偏移为 <code>t*dim</code> ,综上，该位置的cache为 <code>s-&gt;key_cache + loff + h * head_size + t * dim</code></li><li>计算 $att(t)&#x3D;\sum_{i&#x3D;0}^{head\_dim}Q_i*K_i&#x2F;\sqrt{head\_dim}$ ，其维度为 <code>(seq_len, )</code>，但因为仅仅[0, pos]的值为有效的，也即每个已生成的词元都有一个分数。（注意，att数组内容在计算下一个token时被重新填充）</li></ul></li><li>att经过softmax转换为注意力权重 $att&#x3D;softmax(att)$</li><li>接下来一步，是把每个词元的<code>V</code>向量与其对应的<code>att</code>值相乘，然后加总形成一个新的<code>V</code>向量，存储到<code>s-&gt;xb</code>中，计算公式为 $\hat{V}&#x3D;\sum_{t&#x3D;0}^{pos}att(t)*V(t)$，其维度为<code>(head_dim,)</code>与<code>V</code>相同，所以head计算完成之后，维度为<code>(dim,)</code>至此，多头循环结束。</li></ol></li><li><p>注意力最后一步，与 $W^O$ 矩阵相乘，得到该层最终的注意力输出向量<code>(dim,)</code>存储到 <code>s-&gt;xb2</code></p></li><li><p>接下来是 residual 的 <code>Add&amp;Norm</code>，elemwise add 和 rmsnorm，结果存入 <code>s-&gt;xb</code></p> <figure class="highlight c"><figcaption><span>Add&Norm</span><a href="https://github.com/karpathy/llama2.c/blob/4e23ad83995601b63a7697ef27d0ba958480b908/run.c#L304">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="comment">// residual connection back into x</span></span><br><span class="line">accum(x, s-&gt;xb2, dim);</span><br><span class="line"><span class="comment">// ffn rmsnorm</span></span><br><span class="line">rmsnorm(s-&gt;xb, x, w-&gt;rms_ffn_weight + l*dim, dim);</span><br><span class="line">    </span><br></pre></td></tr></table></figure></li><li><p>接下来是FFN网络计算: <code>self.w2(F.silu(self.w1(x)) * self.w3(x))</code></p><ol><li><code>s-&gt;hb=matmul(w-&gt;w1, s-&gt;xb)</code></li><li><code>s-&gt;hb2=matmul(w-&gt;w3, s-&gt;xb)</code></li><li><code>silu(x)=x*σ(x)</code> for <code>s-&gt;hb</code></li><li>elemwise mul <code>s-&gt;hb * s-&gt;hb2</code></li><li>matmul，得到FFN输出，存储在 <code>s-&gt;xb</code></li></ol></li><li><p>layer计算最后一步，residual 的 <code>Add&amp;Norm</code>，注意该实现中rmsnorm放到了layer循环的最开始，这样除最后一层外都会residual add之后执行rmsnorm，而最后一层则放在classifier 的rmsnorm。至此，layer循环结束</p></li></ol></li><li>Classifier 前面的 final rmsnorm， 就是针对最后一层residual的结果做rmsnorm，存入 <code>s-&gt;x</code>b 中</li><li>classifier into logits ，是个Linear层，从(dim,) → (vocab_size,) 的转换， 就是一个matmul: (vacob_size, dim) * (dim,1) → (vocab_size, 1) 结果就是logits，对应字典里每个token的分数。</li></ol><h1 id="其它函数"><a href="#其它函数" class="headerlink" title="其它函数"></a>其它函数</h1><h2 id="rmsnorm"><a href="#rmsnorm" class="headerlink" title="rmsnorm"></a><code>rmsnorm</code></h2><p>The RMS normalization (RMSNorm) is calculated using the following equation:</p><p>$$<br>y&#x3D;\frac{x}{\sqrt{\frac{1}{N}\sum_{i&#x3D;1}^{N}x_i^2+\varepsilon}}<br>$$</p><p>Where:</p><ul><li>$x$ is the input vector</li><li>$N$ is the dimension of the input vector $x$</li><li>$\varepsilon$ is a small number for numerical stability (typically $1e-8$)</li></ul><h2 id="matmul"><a href="#matmul" class="headerlink" title="matmul"></a><code>matmul</code></h2><p>矩阵和向量乘：</p><p>$$<br>\mathbf{y} &#x3D; \mathbf{W} \mathbf{x}<br>$$</p><p>其中：</p><ul><li>$\mathbf{y}(d,1)$ 是结果向量</li><li>$\mathbf{W}(d,n)$ 是矩阵</li><li>$\mathbf{x}(n,1)$ 是乘数向量</li></ul><figure class="highlight c"><figcaption><span>矩阵向量乘</span><a href="https://github.com/karpathy/llama2.c/blob/4e23ad83995601b63a7697ef27d0ba958480b908/run.c#L194">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">void</span> <span class="title function_">matmul</span><span class="params">(<span class="type">float</span>*xout, <span class="type">float</span>* x, <span class="type">float</span>*w, <span class="type">int</span> n, <span class="type">int</span> d)</span> &#123;</span><br><span class="line">    <span class="comment">// W (d,n) @ x (n,) -&gt; xout (d,)</span></span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for private(i)</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; d; i++) &#123;</span><br><span class="line">        <span class="type">float</span> val = <span class="number">0.0f</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">            val += w[i * n + j]* x[j];</span><br><span class="line">        &#125;</span><br><span class="line">        xout[i] = val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如下是各模型 <code>matmul</code> 调用情况</p><table><thead><tr><th>模型</th><th>dim</th><th>n_layers</th><th>n_heads</th><th>hidden_dim</th><th>seq len</th><th>(d,n)</th><th>call num&#x2F;per token</th><th>desc</th></tr></thead><tbody><tr><td>stories15M.bin</td><td>288</td><td>6</td><td>6</td><td>768</td><td>256</td><td>(288,288)</td><td>4x6&#x3D;24</td><td>(layer, dim, dim) Q、K、V、O matmul</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(288,768)</td><td>2x6&#x3D;12</td><td>(dim,hidden_dim) W1、W3</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(768,288)</td><td>1x6&#x3D;6</td><td>(hidden_dim,dim) W2</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(32000,288)</td><td>1x1&#x3D;1</td><td>(vocab_size,dim) classifier</td></tr><tr><td>stories42M.bin</td><td>512</td><td>8</td><td>8</td><td>1376</td><td>1024</td><td>(512,512)</td><td>4x8&#x3D;32</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(1376,512)</td><td>2x8&#x3D;16</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(512,1376)</td><td>1x8&#x3D;8</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(32000,512)</td><td>1x1&#x3D;1</td><td></td></tr><tr><td>stories110M.bin</td><td>768</td><td>12</td><td>12</td><td>2048</td><td>1024</td><td>(768,768)</td><td>4x12&#x3D;48</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(2048,768)</td><td>2x12&#x3D;24</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(768,2048)</td><td>1x12&#x3D;12</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>(32000,768)</td><td>1x1&#x3D;1</td><td></td></tr></tbody></table><h2 id="RoPE"><a href="#RoPE" class="headerlink" title="RoPE"></a><code>RoPE</code></h2><p>RoPE（旋转位置嵌入）的计算公式：</p><p>$$<br>E_{(pos, 2i)} &#x3D; sin(pos &#x2F; 10000^{2i&#x2F;d})<br>$$</p><p>$$<br>E_{(pos, 2i+1)} &#x3D; cos(pos &#x2F; 10000^{2i&#x2F;d})<br>$$</p><p>其中：</p><ul><li>$pos$ 是位置序号，代表词在句子中的位置</li><li>$d$ 是词向量维度（通常经过word embedding后是512）</li><li>$2i$ 对应 $d$ 中的偶数维数，$2i+1$ 对应 $d$ 中的奇数维度</li></ul><p>计算代码如下 <code>freq_cis_real</code> <em>(<code>cos</code>)和 <code>freq_cis_imag</code> (<code>sin</code>)分别存储了维度为<code>(seq_len, dim/2)</code> 偶数和奇数维度的位置参数（训练参数？），这些参数所有head共享，计算过程是遍历每个head重新计算带位置信息的<code>q</code> 和 <code>k</code> 。</em></p><figure class="highlight c"><figcaption><span>`RoPE`计算过程</span><a href="https://github.com/karpathy/llama2.c/blob/4e23ad83995601b63a7697ef27d0ba958480b908/run.c#L234">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// pluck out the &quot;pos&quot; row of freq_cis_real and freq_cis_imag</span></span><br><span class="line"><span class="type">float</span>* freq_cis_real_row = w-&gt;freq_cis_real + pos * head_size / <span class="number">2</span>;</span><br><span class="line"><span class="type">float</span>* freq_cis_imag_row = w-&gt;freq_cis_imag + pos * head_size / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// apply RoPE rotation to the q and k vectors for each head</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> h = <span class="number">0</span>; h &lt; p-&gt;n_heads; h++) &#123;</span><br><span class="line">    <span class="comment">// get the q and k vectors for this head</span></span><br><span class="line marked">    <span class="type">float</span>* q = s-&gt;q + h * head_size;</span><br><span class="line marked">    <span class="type">float</span>* k = s-&gt;k + h * head_size;</span><br><span class="line">    <span class="comment">// rotate q and k by the freq_cis_real and freq_cis_imag</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; head_size; i+=<span class="number">2</span>) &#123;</span><br><span class="line">        <span class="type">float</span> q0 = q[i];</span><br><span class="line">        <span class="type">float</span> q1 = q[i+<span class="number">1</span>];</span><br><span class="line">        <span class="type">float</span> k0 = k[i];</span><br><span class="line">        <span class="type">float</span> k1 = k[i+<span class="number">1</span>];</span><br><span class="line">        <span class="type">float</span> fcr = freq_cis_real_row[i/<span class="number">2</span>];</span><br><span class="line">        <span class="type">float</span> fci = freq_cis_imag_row[i/<span class="number">2</span>];</span><br><span class="line marked">        q[i]   = q0 * fcr - q1 * fci;</span><br><span class="line marked">        q[i+<span class="number">1</span>] = q0 * fci + q1 * fcr;</span><br><span class="line marked">        k[i]   = k0 * fcr - k1 * fci;</span><br><span class="line marked">        k[i+<span class="number">1</span>] = k0 * fci + k1 * fcr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a><code>softmax</code></h2><p>llama2.c 的实现形式:</p> <!-- to solve the {{}} parse error -->$$\sigma(x_i) = \frac{e^{{x_i}-x_{max}}}{\sum_{j=1}^{N} e^{{x_j}-{x_{max}}}}$$<p>简化版本为</p>$$\sigma(x_i)=\frac{e^{x_i}}{\sum_{j=1}^{N} e^{x_j}}$$<p>Where:</p><ul><li>$x$ is the input vector</li><li>$i$ is the element of the input vector $x$</li><li>$N$ is the number of elements</li></ul><figure class="highlight c"><figcaption><span>softmax计算</span><a href="https://github.com/karpathy/llama2.c/blob/4e23ad83995601b63a7697ef27d0ba958480b908/run.c#L174">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">void</span> <span class="title function_">softmax</span><span class="params">(<span class="type">float</span>* x, <span class="type">int</span> size)</span> &#123;</span><br><span class="line">    <span class="comment">// find max value (for numerical stability)</span></span><br><span class="line">    <span class="type">float</span> max_val = x[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (x[i] &gt; max_val) &#123;</span><br><span class="line">            max_val = x[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// exp and sum</span></span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        x[i] = expf(x[i] - max_val);</span><br><span class="line">        sum += x[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// normalize</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        x[i] /= sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="关键数据结构"><a href="#关键数据结构" class="headerlink" title="关键数据结构"></a>关键数据结构</h1><h2 id="kv-cache内存结构"><a href="#kv-cache内存结构" class="headerlink" title="kv_cache内存结构"></a><code>kv_cache</code>内存结构</h2><p><code>key_cache</code>, <code>value_cache</code>维度为<code>(n_layers, seq_len, dim)</code>, 分开存储在如下所示的内存结构里</p><table><thead><tr><th>layer-0</th><th></th><th></th><th></th><th>layer-1</th><th></th><th></th><th></th><th>…</th><th>layer-n</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td><td>…</td><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td></tr><tr><td><code>(dim,)</code></td><td><code>(dim,)</code></td><td>…</td><td><code>(dim,)</code></td><td><code>(dim,)</code></td><td><code>(dim,)</code></td><td>…</td><td><code>(dim,)</code></td><td>…</td><td><code>(dim,)</code></td><td><code>(dim,)</code></td><td>…</td><td><code>(dim,)</code></td></tr></tbody></table><p>多头则是在<code>dim</code>维度再做拆分，则如下所示</p><table><thead><tr><th>layer-0</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>layer-1</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>…</th><th>layer-n</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>token-0</td><td></td><td></td><td></td><td>token-1</td><td></td><td></td><td></td><td>…</td><td>token-k</td><td></td><td></td><td></td><td>token-0</td><td></td><td></td><td></td><td>token-1</td><td></td><td></td><td></td><td>…</td><td>token-n</td><td></td><td></td><td></td><td>…</td><td>token-0</td><td></td><td></td><td></td><td>token-1</td><td></td><td></td><td></td><td>…</td><td>token-k</td><td></td><td></td><td></td></tr><tr><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>…</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>…</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>…</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td><td>…</td><td>head-0</td><td>head-1</td><td>…</td><td>head-m</td></tr><tr><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td><td><code>(head_dim,)</code></td><td>…</td><td><code>(head_dim,)</code></td></tr></tbody></table><h2 id="checkpoint文件"><a href="#checkpoint文件" class="headerlink" title="checkpoint文件"></a><code>checkpoint</code>文件</h2><p>该文件存储了<code>Transformer</code>模型配置及权重信息，主要分两部分，数据按照二进制紧挨着存储，其中权重各子项的offset可由config相关维度信息计算得出。</p><ul><li>Config struct，全是4字节 <code>int</code> 的维度信息，主要包括dim, hidden_dim, n_layers, n_heads, n_kv_heads, vocab_size, seq_len等</li><li>全是4字节 <code>float</code> 的权重信息，主要包括embedding table，attention的Q&#x2F;K&#x2F;V&#x2F;O，FFN的权重，RoPE，RMS，classifier等权重</li></ul><p>如下是15M参数量的OG模型配置信息</p><table><thead><tr><th>config</th><th></th><th></th><th></th><th></th><th></th><th></th><th>token embedding table</th><th>weights for rmsnorm</th><th></th><th>weights for atten</th><th></th><th></th><th></th><th>wights for ffn</th><th></th><th></th><th>final rmsnorm</th><th>RoPE</th><th></th><th>classifier</th></tr></thead><tbody><tr><td>dim</td><td>hidden_dim</td><td>n_layers</td><td>n_heads</td><td>n_kv_heads</td><td>vocab_size</td><td>seq_len</td><td>token_embedding_table</td><td>rms_att_weight</td><td>rms_ffn_weight</td><td>wq</td><td>wk</td><td>wv</td><td>wo</td><td>w1</td><td>w2</td><td>w3</td><td>rms_final_weight</td><td>freq_cis_real</td><td>freq_cis_imag</td><td>wcls</td></tr><tr><td>288</td><td>768</td><td>6</td><td>6</td><td>6</td><td>32000</td><td>256</td><td>(vocab_size, dim) → (32000, 288)</td><td>(n_layers, dim) → (6, 288)</td><td>(n_layers, dim) → (6, 288)</td><td>(n_layers, dim, dim) → (6, 288, 288)</td><td>(n_layers, dim, dim) → (6, 288, 288)</td><td>(n_layers, dim, dim) → (6, 288, 288)</td><td>(n_layers, dim, dim) → (6, 288, 288)</td><td>(n_layers, hidden_dim, dim) → (6, 768, 288)</td><td>(n_layers, dim, hidden_dim) → (6, 288, 768)</td><td>(n_layers, hidden_dim, dim) → (6, 768, 288)</td><td>(dim, ) → (288,)</td><td>(seq_len, dim&#x2F;2) → (256, 288&#x2F;2)</td><td>(seq_len, dim&#x2F;2) → (256, 288&#x2F;2)</td><td>(vocab_size, hidden_size) <em>(hidden_size, 1) → (32000, 768)</em> (768,1)</td></tr></tbody></table><ol><li>token embedding table</li></ol><p>是维度为 (vacab_size, dim)的数组，所以token 是该pos处对应的词元在vocab里面的索引，每个token对应一个(dim,) 大小的向量，该实现中应是为了简化，词元向量大小与Q&#x2F;K&#x2F;V向量大小一致，也即<code>dim</code> 。在其它实现中会不一样，一般是 token_len &gt; dim，比如把词元embedding之后是(256,)的向量，然后压缩为(288,)的向量。</p><h2 id="tokenizer文件"><a href="#tokenizer文件" class="headerlink" title="tokenizer文件"></a><code>tokenizer</code>文件</h2><p>该文件保存的是总共 <code>vocab_size</code> 个token，每个token包含2部分，前面是4个字节 <code>int</code> 型的token长度，紧接着是token内容（不包括结束符的字符串），如下图，所有token一个挨一个存储。</p><blockquote><p><code>vocab_size</code> 存储在 <code>checkpoint</code> 文件里。</p></blockquote><table><thead><tr><th>token len</th><th>token content</th><th>token len</th><th>token content</th><th>…</th><th>token len</th><th>token content</th></tr></thead><tbody><tr><td>1</td><td>l</td><td>4</td><td>like</td><td></td><td>11</td><td>suggestions</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li><p>简单来讲，注意力，就是针对每个词元，计算其它<strong>已有</strong>词元与其的<strong>关系</strong>，即两两得到一个注意力分数，所以每个词元最终对应一个 <code>(seq_len,)</code> 的向量，有效部分是 <code>[0, pos]</code> 也就是该词元及其前面的位置。因为要预测下一个位置，所以还需要把每个词元的注意力分数作为权重与其自身的 <code>V</code> 相乘，然后按元素相加得到一个新的 <code>V</code>,用来预测下一个词元。再具体点，就是两两词元的Q与K点积得到一个值（即注意力分数），然后作为其V的权重，把所有V按元素相加合并成一个新的V，再经过FFN、Classifier即可预测下一个词元。</p></li><li><p>注意力计算公式也简单：</p> <img src="/images/llama2/transformer_func.png" class="" width="319" height="188"></li><li><p>multi-head 拆分是在 <code>dim</code>维度，每个head的 <code>head_dim</code> 加总等于 <code>dim</code> 。拆分之后，att 的计算仅限于 <code>head_dim</code> 内部进行，也即上述公式中的 ${d_k}&#x3D;head\_dim$，head 之间互不干涉。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;基于源码调试过程，以及如下两篇文章整理。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This repo is line by line walk through of the inference file in llama2.c. Its very verbose &amp;amp; intended for beginners.&lt;br&gt;You will need some familiarity with transformers architecture. If you are a complete novice refer to this excellent blog first.&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;RahulSChand&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;https://github.com/RahulSChand/llama2.c-for-dummies&quot;&gt;cllama2.c-for-dummies&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;The Illustrated Transformer。&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;jalammar&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;https://jalammar.github.io/illustrated-transformer&quot;&gt;illustrated-transformer&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;

&lt;p&gt;llama2.c 包含了训练代码和推理实现，作者提供了如下几个预训练模型，可以直接运行 run 这个demo程序生成一个简短的小故事。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;model&lt;/th&gt;
&lt;th&gt;dim&lt;/th&gt;
&lt;th&gt;n_layers&lt;/th&gt;
&lt;th&gt;n_heads&lt;/th&gt;
&lt;th&gt;n_kv_heads&lt;/th&gt;
&lt;th&gt;max context length&lt;/th&gt;
&lt;th&gt;parameters&lt;/th&gt;
&lt;th&gt;val loss&lt;/th&gt;
&lt;th&gt;download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;260K&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;260K&lt;/td&gt;
&lt;td&gt;1.297&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://huggingface.co/karpathy/tinyllamas/tree/main/stories260K&quot;&gt;https://huggingface.co/karpathy/tinyllamas/tree/main/stories260K&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OG&lt;/td&gt;
&lt;td&gt;288&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;15M&lt;/td&gt;
&lt;td&gt;1.072&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin&quot;&gt;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;42M&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;1024&lt;/td&gt;
&lt;td&gt;42M&lt;/td&gt;
&lt;td&gt;0.847&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin&quot;&gt;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;110M&lt;/td&gt;
&lt;td&gt;768&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;1024&lt;/td&gt;
&lt;td&gt;110M&lt;/td&gt;
&lt;td&gt;0.760&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin&quot;&gt;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;与一般的问答式文本生成不一样, &lt;code&gt;run&lt;/code&gt; 的实现做了简化，首先是没有prompt 输入而是每次运行直接生成一个tiny story，所以也就没有针对prompt 做embedding 的 init_prefill 计算阶段，而只有 generate；其次是在生成的迭代过程中，主要的transformer计算输入输出只需要词元的 &lt;code&gt;token&lt;/code&gt; 因此预先把所有词元的embedding存储在&lt;code&gt;token_embedding_table&lt;/code&gt; 中，迭代过程中直接从里面读取当前位置的 embedding 参与计算，推理过程中可以省掉输入词元的embedding计算过程。&lt;/p&gt;
&lt;p&gt;涉及到的输入文件有模型checkpoint如 &lt;code&gt;stories15M.bin&lt;/code&gt; ，以及tokenizer 文件 &lt;code&gt;tokenizer.bin&lt;/code&gt; ，具体的文件结构可以参考文末的分析。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://waterdropw.github.io/categories/AI/"/>
    
    <category term="transformer" scheme="https://waterdropw.github.io/categories/AI/transformer/"/>
    
    <category term="self-attention" scheme="https://waterdropw.github.io/categories/AI/transformer/self-attention/"/>
    
    
    <category term="AI" scheme="https://waterdropw.github.io/tags/AI/"/>
    
    <category term="transformer" scheme="https://waterdropw.github.io/tags/transformer/"/>
    
    <category term="self-attention" scheme="https://waterdropw.github.io/tags/self-attention/"/>
    
  </entry>
  
  <entry>
    <title>极简`Transformer`实现(基于`llama2.c`commit-b3c4b6c 24&#39;2/13)</title>
    <link href="https://waterdropw.github.io/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-b3c4b6c/"/>
    <id>https://waterdropw.github.io/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-b3c4b6c/</id>
    <published>2024-04-17T02:34:26.000Z</published>
    <updated>2025-11-20T11:50:20.178Z</updated>
    
    <content type="html"><![CDATA[<p>与早期版本（详情可以参考这里：<a href="/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-4e23ad8/" title="极简&#96;Transformer&#96;实现(基于&#96;llama2.c&#96;commit-4e23ad 23&#39;7&#x2F;27)">4e23ad8 23&#39;7&#x2F;27</a>）不同，目前的版本有两种模式，一是<strong>generate</strong>， 根据给定的prompt生成一个简短的英文小故事。二是<strong>chat</strong>， 需要输入system prompt和问题，生成一个回答并退出，没有多轮对话，并且回答与问题没有太大关联性而且有不少问题（尤其是15M模型），所以该模式还不完善，并且有一个 <a href="https://github.com/karpathy/llama2.c/tree/feature/chat" title="feature&#x2F;chat" target="">feature&#x2F;chat</a> 分支处于开发中有兴趣可以关注该分支。我们主要关注代码更新的部分。</p><h1 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h1><p>该版本代码进行了重构，sampler封装到结构体里，其次把分阶段的执行流程各自封装到函数里面，调用逻辑会更清晰一些。同样的，<code>main</code>主要处理命令行参数，然后是模型推理流程。</p><h2 id="main-执行流程"><a href="#main-执行流程" class="headerlink" title="main 执行流程"></a><code>main</code> 执行流程</h2><ol><li>解析命令行参数，包括 checkpoint 文件路径, temperature, steps等。</li><li>调用<code>build_transformer</code>，会调用<code>read_checkpoint</code>加载checkpoint 文件内容，包括模型配置和权重。其次调用<code>malloc_run_state</code>初始化运行时变量，包括kv cache等。注意，这里没有再对<code>s-&gt;k</code>, <code>s-&gt;v</code>分配内存，直接指向kv cache相应的位置，省掉一次内存拷贝操作。</li><li>调用<code>build_tokenizer</code>，加载<code>tokenizer.bin</code>。</li><li>调用<code>build_sampler</code>，初始化采样对象。</li><li>接下来就是根据给定运行模式，调用<code>generate</code>或者<code>chat</code>执行生成或问答流程。</li><li>内存清理并退出</li></ol><h2 id="generate"><a href="#generate" class="headerlink" title="generate"></a><code>generate</code></h2><p>计算过程：</p><ol><li>首先调用<code>encode</code>，把用户输入的<strong>prompt</strong>编码为token，存储到<code>prompt_tokens</code>，维度为<code>(strlen(prompt)+3,)</code>的int数组。</li><li>然后从<code>prompt_tokens</code>的第一个token开始（通常是BOS）执行主循环生成文本，即根据给定的**seq_len(steps)**执行循环 <code>[0, steps]</code>：<ol><li>调用<code>forward</code>得到当前位置<code>pos</code>的<code>logits</code><ol><li>如果当前词元还是prompt，则从prompt里面取下一个token</li><li>否则，根据logits调用<code>sample</code>采样得到下一个token</li></ol></li><li>如果下一个token是BOS，则终止循环。</li><li>调用<code>decode</code>从tokenizer里面解码得到token对应的单词，并打印。</li><li>继续下一个循环</li></ol></li><li>生成完毕，释放<code>prompt_tokens</code>临时堆内存</li></ol><h2 id="chat"><a href="#chat" class="headerlink" title="chat"></a><code>chat</code></h2><p>Todo：</p><h2 id="forward"><a href="#forward" class="headerlink" title="forward"></a><code>forward</code></h2><p>模型推理的计算都封装到该函数里了，具体计算过程与<a href="/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-4e23ad8/" title="极简&#96;Transformer&#96;实现(基于&#96;llama2.c&#96;commit-4e23ad 23&#39;7&#x2F;27)">4e23ad8 23&#39;7&#x2F;27</a>里面的<code>transformer</code>基本类似，差异是增加了对**Multi-Query Attention(MQA)<strong>和</strong>Grouped-Query Attention(GQA)**的支持。<br>先看下<code>MHA</code>、<code>MQA</code>及<code>GQA</code>之间的区别，</p><img src="/images/llama2/mha_mqa_gqa.jpg" class="" width="600" height="408" title="MHA&#x2F;MQA&#x2F;GQA"><p>在该代码实现里，</p><ol><li>如果<code>n_kv_heads==n_heads</code>则为MHA，每个query都对应一组独立的key和value。</li><li>如果<code>n_kv_heads==1</code>则为MQA，所有query对应一组key和value。</li><li>否则<code>1&lt;n_kv_heads&lt;n_heads</code>则为GQA，多个query对应一组key和value，并且不止一组。</li></ol><p>具体的代码实现流程如下：</p><ol><li>初始化局部变量，新增<code>kv_dim = dim/n_heads * n_kv_heads = head_dim * n_kv_heads</code>，因为要跟query保持一致，所以kv head的<code>head_dim</code>也是<code>head_dim = dim/n_heads</code>固定的与<code>n_kv_heads</code>无关。补充一下，这里<code>kv_dim</code>代表每个token对应在kv cache里面的偏移大小或者说是每个token的dim维度，具体可以参考后面<strong>kv_cache内存结构</strong>。接下来进入正题，从<code>token_embedding_table</code>中取出当前token的embedding<code>(dim, )</code> 放入 <code>s-&gt;x</code> 中作为模型输入。</li><li>循环遍历每一层<code>for l in 0..n_layers</code>：<ol><li>对<code>s-&gt;x</code>计算<code>rmsnorm</code>并存入 <code>s-&gt;xb</code>；计算该层kv cache偏移，<code>loff=l*seq_len*kv_dim</code>，如上分析，kv_dim就是每个token的维度。</li><li>计算 Q、K、V，结果直接存入 <code>s-&gt;q</code>, <code>s-&gt;k</code>, <code>s-&gt;v</code>，而后两者是指向kv cache当前位置的，所以省掉一次内存拷贝。</li><li>计算<code>RoPE</code>编码的Q、K，结果存入 <code>s-&gt;q</code>, <code>s-&gt;k</code>。注意这里的改进，多头合在一起一并计算，效率更高。</li><li>计算多头注意力，循环遍历每个头<code>for h in 0..n_heads</code>:<ol><li>Q起始位置，Q原始维度<code>(dim, )</code>拆分多头后为<code>(n_heads, head_dim)</code>，所以第<code>h</code>头的起始位置为**<code>float* q = s-&gt;q + h * head_size</code></li><li>atten score <code>(n_heads, seq_len)</code>，因为是按头存放的，所以在第<code>h</code>头的起始位置就是 <code>s-&gt;att + h * p-&gt;seq_len</code></li><li>kv cache在<code>dim</code>维度拆分多头，并考虑<code>MQA/GQA</code>后维度为<code>(layer, seq_len, n_kv_heads, head_dim)</code>或者简化为<code>(layer, seq_len, kv_dim)</code>，因为<code>n_kv_heads &lt;= n_heads</code>要均分共享，这里的关键是需要计算query的第h个head对应的kv cache偏移在哪里。代码实现里面有个小技巧，我们先来看sequence维度，<code>t</code>位置的偏移为<code>t * kv_dim</code>，这个好理解，前面已经讲过，然后再计算<code>kv_dim</code>里面的偏移是多少，这里会用到临时变量<code>kv_mul = n_kv_heads / n_heads</code>, 则query第<code>h</code>头在第<code>t</code>个token维度内也就是<code>kv_dim</code>内，偏移为<code>(h/kv_mul) * head_size</code>。</li><li>计算该词元对<strong>它之前所有</strong>词元的注意力分数（包含自己），其实就是masked attention，<code>for t in 0..pos+1</code>:<ul><li>第 <code>t</code> 个词元对应在第 <code>h</code> 头内的偏移为 <code>t * kv_dim</code>，这个好理解，前面已经讲过。综上，<code>t</code>位置的cache为 <code>s-&gt;key_cache + loff + (h/kv_mul) * head_size + t * kv_dim</code>。</li><li>计算 $att(t)&#x3D;\sum_{i&#x3D;0}^{head\_dim}Q_i*K_i&#x2F;\sqrt{head\_dim}$ ，其维度为 <code>(seq_len, )</code>，但因为仅仅<code>[0, pos]</code>的值为有效的，也即每个已生成的词元都有一个分数。（注意，att数组内容在计算下一个token时被重新填充）</li></ul></li><li>att经过softmax转换为注意力权重 $att&#x3D;softmax(att)$</li><li>接下来一步，是把每个词元的<code>V</code>向量与其对应的<code>att</code>值相乘，然后加总形成一个新的<code>V</code>向量，存储到<code>s-&gt;xb</code>中，计算公式为 $\hat{V}&#x3D;\sum_{t&#x3D;0}^{pos}att(t)*V(t)$，其维度为<code>(head_dim,)</code>与<code>V</code>相同，所以head计算完成之后，维度为<code>(dim,)</code>至此，多头循环结束。</li></ol></li><li>注意力最后一步，与 $W^O$ 矩阵相乘，得到该层最终的注意力输出向量 (dim, )，存储到 <code>s-&gt;xb2</code></li><li>接下来是 residual 的 <code>Add&amp;Norm</code>，elemwise add 和 rmsnorm，结果存入 <code>s-&gt;xb</code></li><li>接下来是FFN网络计算: <code>self.w2(F.silu(self.w1(x)) * self.w3(x))</code><ol><li><code>s-&gt;hb=matmul(w-&gt;w1, s-&gt;xb)</code></li><li><code>s-&gt;hb2=matmul(w-&gt;w3, s-&gt;xb)</code></li><li><code>silu(x)=x*σ(x)</code> for <code>s-&gt;hb</code></li><li>elemwise mul <code>s-&gt;hb * s-&gt;hb2</code></li><li>matmul，得到FFN输出，存储在 <code>s-&gt;xb</code></li></ol></li><li>layer计算最后一步，residual 的 <code>Add&amp;Norm</code>，注意该实现中rmsnorm放到了layer循环的最开始，这样除最后一层外都会residual add之后执行rmsnorm，而最后一层则放在classifier 的rmsnorm。至此，layer循环结束</li></ol></li><li>Classifier 前面的 final rmsnorm， 就是针对最后一层residual的结果做rmsnorm，存入 <code>s-&gt;x</code>b 中</li><li>classifier into logits ，是个Linear层，从(dim,) → (vocab_size,) 的转换， 就是一个matmul: (vacob_size, dim) * (dim,1) → (vocab_size, 1) 结果就是logits，对应字典里每个token的分数。</li></ol><h1 id="其它函数"><a href="#其它函数" class="headerlink" title="其它函数"></a>其它函数</h1><h2 id="build-transformer"><a href="#build-transformer" class="headerlink" title="build_transformer"></a><code>build_transformer</code></h2><p>做了两件事情：</p><ol><li>读取<code>checkpoint</code>文件并解析<strong>模型配置参数</strong>和<strong>权重参数</strong>，存入结构体变量<code>t</code>里。<code>checkpoint</code>文件结构详见上一篇文章。</li><li>初始化运行时的<code>RunState</code>结构体，分配内存空间，包括模型输入输出，attention分数，kv cache等。<blockquote><p>注：<code>t-&gt;s-&gt;k</code>和<code>t-&gt;s-&gt;v</code>不分配内存空间，计算是直接读取kv cache对应的内存区域。这个跟之前的版本有区别。</p></blockquote></li></ol><figure class="highlight c"><figcaption><span>build_transformer</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L164">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">void</span> <span class="title function_">build_transformer</span><span class="params">(Transformer *t, <span class="type">char</span>* checkpoint_path)</span> &#123;</span><br><span class="line">    <span class="comment">// read in the Config and the Weights from the checkpoint</span></span><br><span class="line">    read_checkpoint(checkpoint_path, &amp;t-&gt;config, &amp;t-&gt;weights, &amp;t-&gt;fd, &amp;t-&gt;data, &amp;t-&gt;file_size);</span><br><span class="line">    <span class="comment">// allocate the RunState buffers</span></span><br><span class="line">    malloc_run_state(&amp;t-&gt;state, &amp;t-&gt;config);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="build-tokenizer"><a href="#build-tokenizer" class="headerlink" title="build_tokenizer"></a><code>build_tokenizer</code></h2><p>tokenizer文件结构详见后面章节，注意跟之前的版本有差别且不兼容。此外新增了</p><ul><li><code>vocab_scores</code>维度<code>(vocab_size,)</code></li><li><code>byte_pieces</code>维度<code>(512,)</code>，初始化为 0~255 字符每个都带’\0’结尾隔开，总共512个字符。</li></ul><p>该函数代码基本上就是文件和内存操作，初始化<code>Tokenizer</code>结构体，具体来说就是把<code>tokenizer.bin</code>文件读取到内存中，总共<code>32k</code>个词元字符串，每个词元开辟一块字符串数组内存区域单独存储，所有字符串指针放到一个数组里，可以按顺序遍历，也就是给定token，作为index即可取出对应词元的字符串。</p><blockquote><p>文件结构详细信息可参考上一篇文章。</p></blockquote><figure class="highlight c"><figcaption><span>Tokenizer</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L364">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ----------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">// The Byte Pair Encoding (BPE) Tokenizer that translates strings &lt;-&gt; tokens</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> *str;</span><br><span class="line">    <span class="type">int</span> id;</span><br><span class="line marked">&#125; TokenIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">char</span>** vocab;</span><br><span class="line">    <span class="type">float</span>*vocab_scores;</span><br><span class="line">    TokenIndex*sorted_vocab;</span><br><span class="line">    <span class="type">int</span> vocab_size;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> max_token_length;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> byte_pieces[<span class="number">512</span>]; <span class="comment">// stores all single-byte strings</span></span><br><span class="line marked">&#125; Tokenizer;</span><br></pre></td></tr></table></figure><figure class="highlight c"><figcaption><span>build_tokenizer</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L385">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">void</span> <span class="title function_">build_tokenizer</span><span class="params">(Tokenizer*t, <span class="type">char</span>* tokenizer_path, <span class="type">int</span> vocab_size)</span> &#123;</span><br><span class="line">    <span class="comment">// i should have written the vocab_size into the tokenizer file... sigh</span></span><br><span class="line">    t-&gt;vocab_size = vocab_size;</span><br><span class="line">    <span class="comment">// malloc space to hold the scores and the strings</span></span><br><span class="line">    t-&gt;vocab = (<span class="type">char</span>**)<span class="built_in">malloc</span>(vocab_size *<span class="keyword">sizeof</span>(<span class="type">char</span>*));</span><br><span class="line">    t-&gt;vocab_scores = (<span class="type">float</span>*)<span class="built_in">malloc</span>(vocab_size* <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    t-&gt;sorted_vocab = <span class="literal">NULL</span>; <span class="comment">// initialized lazily</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++) &#123;</span><br><span class="line">        t-&gt;byte_pieces[i * <span class="number">2</span>] = (<span class="type">unsigned</span> <span class="type">char</span>)i;</span><br><span class="line">        t-&gt;byte_pieces[i * <span class="number">2</span> + <span class="number">1</span>] = <span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// read in the file</span></span><br><span class="line">    FILE *file = fopen(tokenizer_path, <span class="string">&quot;rb&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (!file) &#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;couldn&#x27;t load %s\n&quot;</span>, tokenizer_path); <span class="built_in">exit</span>(EXIT_FAILURE); &#125;</span><br><span class="line">    <span class="keyword">if</span> (fread(&amp;t-&gt;max_token_length, <span class="keyword">sizeof</span>(<span class="type">int</span>), <span class="number">1</span>, file) != <span class="number">1</span>) &#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed read\n&quot;</span>); <span class="built_in">exit</span>(EXIT_FAILURE); &#125;</span><br><span class="line">    <span class="type">int</span> len;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vocab_size; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (fread(t-&gt;vocab_scores + i, <span class="keyword">sizeof</span>(<span class="type">float</span>), <span class="number">1</span>, file) != <span class="number">1</span>) &#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed read\n&quot;</span>); <span class="built_in">exit</span>(EXIT_FAILURE);&#125;</span><br><span class="line">        <span class="keyword">if</span> (fread(&amp;len, <span class="keyword">sizeof</span>(<span class="type">int</span>), <span class="number">1</span>, file) != <span class="number">1</span>) &#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed read\n&quot;</span>); <span class="built_in">exit</span>(EXIT_FAILURE); &#125;</span><br><span class="line">        t-&gt;vocab[i] = (<span class="type">char</span>*)<span class="built_in">malloc</span>(len + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (fread(t-&gt;vocab[i], len, <span class="number">1</span>, file) != <span class="number">1</span>) &#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed read\n&quot;</span>); <span class="built_in">exit</span>(EXIT_FAILURE); &#125;</span><br><span class="line">        t-&gt;vocab[i][len] = <span class="string">&#x27;\0&#x27;</span>; <span class="comment">// add the string terminating token</span></span><br><span class="line">    &#125;</span><br><span class="line">    fclose(file);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="build-sampler"><a href="#build-sampler" class="headerlink" title="build_sampler"></a><code>build_sampler</code></h2><p>该版本将<code>logits</code>到文本字符串的采样过程重新做了封装，相关参数放到了<code>Sampler</code>结构体里。其次新增了<code>ProbIndex</code>以支持<strong>top-p</strong>采样方式，总共支持三种采样方式：</p><ol><li>贪心算法，argmax取最大值</li><li>随机采样</li><li>topp采样</li></ol><figure class="highlight c"><figcaption><span>Sampler</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L573">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ----------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">// The Sampler, which takes logits and returns a sampled token</span></span><br><span class="line"><span class="comment">// sampling can be done in a few ways: greedy argmax, sampling, top-p sampling</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">float</span> prob;</span><br><span class="line">    <span class="type">int</span> index;</span><br><span class="line marked">&#125; ProbIndex; <span class="comment">// struct used when sorting probabilities during top-p sampling</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> vocab_size;</span><br><span class="line">    ProbIndex* probindex; <span class="comment">// buffer used in top-p sampling</span></span><br><span class="line">    <span class="type">float</span> temperature;</span><br><span class="line">    <span class="type">float</span> topp;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> rng_state;</span><br><span class="line marked">&#125; Sampler;</span><br></pre></td></tr></table></figure><p>该函数初始化结构体及分配内存。<code>probindex</code>是维度为<code>(vocab_size,)</code>的<code>ProbIndex</code>结构体数组。</p><figure class="highlight c"><figcaption><span>build_sampler</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L667">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">void</span> <span class="title function_">build_sampler</span><span class="params">(Sampler*sampler, <span class="type">int</span> vocab_size, <span class="type">float</span> temperature, <span class="type">float</span> topp, <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> rng_seed)</span> &#123;</span><br><span class="line">    sampler-&gt;vocab_size = vocab_size;</span><br><span class="line">    sampler-&gt;temperature = temperature;</span><br><span class="line">    sampler-&gt;topp = topp;</span><br><span class="line">    sampler-&gt;rng_state = rng_seed;</span><br><span class="line">    <span class="comment">// buffer only used with nucleus sampling; may not need but it&#x27;s ~small</span></span><br><span class="line">    sampler-&gt;probindex = <span class="built_in">malloc</span>(sampler-&gt;vocab_size* <span class="keyword">sizeof</span>(ProbIndex));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="encode"><a href="#encode" class="headerlink" title="encode"></a><code>encode</code></h2><p>Todo：</p><h2 id="decode"><a href="#decode" class="headerlink" title="decode"></a><code>decode</code></h2><p>解码过程就是<code>token:int -&gt; vocab:str</code>的转换，此处处理了空格及一些特殊符号。</p><figure class="highlight c"><figcaption><span>decode</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L418">run.c</a></figcaption><table><tr><td class="gutter"><pre><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br></pre></td><td class="code"><pre><span class="line marked"><span class="type">char</span>* <span class="title function_">decode</span><span class="params">(Tokenizer* t, <span class="type">int</span> prev_token, <span class="type">int</span> token)</span> &#123;</span><br><span class="line">    <span class="type">char</span> *piece = t-&gt;vocab[token];</span><br><span class="line">    <span class="comment">// following BOS (1) token, sentencepiece decoder strips any leading whitespace (see PR #89)</span></span><br><span class="line">    <span class="keyword">if</span> (prev_token == <span class="number">1</span> &amp;&amp; piece[<span class="number">0</span>] == <span class="string">&#x27; &#x27;</span>) &#123; piece++; &#125;</span><br><span class="line">    <span class="comment">// careful, some tokens designate raw bytes, and look like e.g. &#x27;&lt;0x01&gt;&#x27;</span></span><br><span class="line">    <span class="comment">// parse this and convert and return the actual byte</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> byte_val;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">sscanf</span>(piece, <span class="string">&quot;&lt;0x%02hhX&gt;&quot;</span>, &amp;byte_val) == <span class="number">1</span>) &#123;</span><br><span class="line">        piece = (<span class="type">char</span>*)t-&gt;byte_pieces + byte_val * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> piece;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="sample"><a href="#sample" class="headerlink" title="sample"></a><code>sample</code></h2><p>根据temperature、topp等超参数，将推理输出结果<code>logits</code>采样得到token id。根据超参数值的不同，支持三种采样方式：</p><ol><li><code>temperature == 0.0f</code>，则采用贪心算法，取argmax最大值，返回<code>sample_argmax</code>结果</li><li><code>topp&lt;=0 || topp&gt;=1</code>，随机采样，返回<code>sample_mult</code>结果</li><li>否则 top-p 采样，返回<code>sample_topp</code>结果</li></ol><figure class="highlight c"><figcaption><span>sample</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L691">run.c 691</a></figcaption><table><tr><td class="gutter"><pre><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sample</span><span class="params">(Sampler*sampler, <span class="type">float</span>* logits)</span> &#123;</span><br><span class="line">    <span class="comment">// sample the token given the logits and some hyperparameters</span></span><br><span class="line">    <span class="type">int</span> next;</span><br><span class="line">    <span class="keyword">if</span> (sampler-&gt;temperature == <span class="number">0.0f</span>) &#123;</span><br><span class="line">        <span class="comment">// greedy argmax sampling: take the token with the highest probability</span></span><br><span class="line">        next = sample_argmax(logits, sampler-&gt;vocab_size);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// apply the temperature to the logits</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> q=<span class="number">0</span>; q&lt;sampler-&gt;vocab_size; q++) &#123; logits[q] /= sampler-&gt;temperature; &#125;</span><br><span class="line">        <span class="comment">// apply softmax to the logits to get the probabilities for next token</span></span><br><span class="line">        softmax(logits, sampler-&gt;vocab_size);</span><br><span class="line">        <span class="comment">// flip a (float) coin (this is our source of entropy for sampling)</span></span><br><span class="line">        <span class="type">float</span> coin = random_f32(&amp;sampler-&gt;rng_state);</span><br><span class="line">        <span class="comment">// we sample from this distribution to get the next token</span></span><br><span class="line">        <span class="keyword">if</span> (sampler-&gt;topp &lt;= <span class="number">0</span> || sampler-&gt;topp &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// simply sample from the predicted probability distribution</span></span><br><span class="line">            next = sample_mult(logits, sampler-&gt;vocab_size, coin);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// top-p (nucleus) sampling, clamping the least likely tokens to zero</span></span><br><span class="line">            next = sample_topp(logits, sampler-&gt;vocab_size, sampler-&gt;topp, sampler-&gt;probindex, coin);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sample-argmax"><a href="#sample-argmax" class="headerlink" title="sample_argmax"></a><code>sample_argmax</code></h3><p>循环遍历所有元素，返回最大值的索引。</p><figure class="highlight c"><figcaption><span>sample_argmax</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L590">run.c 590</a></figcaption><table><tr><td class="gutter"><pre><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sample_argmax</span><span class="params">(<span class="type">float</span>* probabilities, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// return the index that has the highest probability</span></span><br><span class="line">    <span class="type">int</span> max_i = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> max_p = probabilities[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (probabilities[i] &gt; max_p) &#123;</span><br><span class="line">            max_i = i;</span><br><span class="line">            max_p = probabilities[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> max_i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sample-mult"><a href="#sample-mult" class="headerlink" title="sample_mult"></a><code>sample_mult</code></h3><p>累加结果超过给定随机值，就返回当前的索引。</p><figure class="highlight c"><figcaption><span>sample_mult</span><a href="https://github.com/karpathy/llama2.c/blob/b3c4b6c3c4bbff42e5211293280307019368ccb5/run.c#L603">run.c 603</a></figcaption><table><tr><td class="gutter"><pre><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sample_mult</span><span class="params">(<span class="type">float</span>* probabilities, <span class="type">int</span> n, <span class="type">float</span> coin)</span> &#123;</span><br><span class="line">    <span class="comment">// sample index from probabilities (they must sum to 1!)</span></span><br><span class="line">    <span class="comment">// coin is a random number in [0, 1), usually from random_f32()</span></span><br><span class="line">    <span class="type">float</span> cdf = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        cdf += probabilities[i];</span><br><span class="line">        <span class="keyword">if</span> (coin &lt; cdf) &#123;</span><br><span class="line">            <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n - <span class="number">1</span>; <span class="comment">// in case of rounding errors</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sample-topp"><a href="#sample-topp" class="headerlink" title="sample_topp"></a><code>sample_topp</code></h3>$$topp(p) = \max{k : \sum_{i=1}^{k} P(w_i) \leq p}$$<p>计算过程：</p><ol><li>首先设定阈值为 <code>float cutoff = (1.0f - topp) / (n-1)</code></li><li>初筛，挑选出概率大于阈值的所有token，其它的舍弃，结果存入<code>probindex</code>数组中。</li><li>再按照概率值降序排列</li><li>细筛，从前往后累加，得到<strong>不大于</strong><code>topp</code>的和<code>cumulative_prob</code>及对应的所以<code>last_idx</code>，然后截取<code>last_idx</code>之前的部分作为候选列表。</li><li>采样，设定阈值<code>float r = coin * cumulative_prob</code>，从候选列表里找累加概率值不大于阈值<code>r</code>的token返回</li></ol><h1 id="关键数据结构"><a href="#关键数据结构" class="headerlink" title="关键数据结构"></a>关键数据结构</h1><h2 id="kv-cache内存结构"><a href="#kv-cache内存结构" class="headerlink" title="kv_cache内存结构"></a><code>kv_cache</code>内存结构</h2><p>首先kv cache每个head的维度必须要与query保持一致才能做点积所以都是：<code>head_dim=dim/n_heads</code>，其次是kv各自有<code>n_kv_heads</code>个head，所以很容易得出kv cache的维度为<code>(n_layers, seq_len, n_kv_heads, head_dim)</code>。那么从layer层面看（尚未区分多头）的话，每个token对应kv的维度就是<code>kv_dim = n_kv_heads * head_dim</code>，其内存结构示意图如下。这跟query（<code>dim</code>）是不一样的，切记切记。相应的，$W_k$, $W_v$权重矩阵维度也变成了<code>(layer, dim, kv_dim)</code>跟Query不一样。切记切记。所以我们可以看到，MQA&#x2F;GQA减少了kv head，实际上是缩小了两个权重矩阵的大小，同时有另外一层隐藏的含义，就是每个token对应的kv dim维度也变小了，也就是信息容量更少了，性能肯定受影响。</p><blockquote><p>注：也许好奇，GQA为何kv总的维度不合q保持一致都是<code>dim</code>，因为<code>head_dim</code>和<code>dim</code>只能有一个相同，否则head数量就得一致，也就是MHA了。</p></blockquote><p>接下来，因为<code>n_kv_heads&lt;=n_heads</code>所以必然有<code>kv_dim</code>是要被多个相邻的query head共享的，举个例子，假如<code>n_heads=6,n_kv_heads=3</code>,则<code>kv_dim = 3 * head_dim</code>, 那么每个kv head会被2个query head共享。所以6个query head对应的kv head索引分别是：(0, 0, 1, 1, 2, 2)，每个长度是<code>head_dim</code>所以加起来正好是<code>kv_dim</code>，相邻两个query对应的kv head是同一个。</p><table><thead><tr><th>layer-0</th><th></th><th></th><th></th><th>layer-1</th><th></th><th></th><th></th><th>…</th><th>layer-n</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td><td>…</td><td>token-0</td><td>token-1</td><td>…</td><td>token-k</td></tr><tr><td><code>(kv_dim,)</code></td><td><code>(kv_dim,)</code></td><td>…</td><td><code>(kv_dim,)</code></td><td><code>(kv_dim,)</code></td><td><code>(kv_dim,)</code></td><td>…</td><td><code>(kv_dim,)</code></td><td>…</td><td><code>(kv_dim,)</code></td><td><code>(kv_dim,)</code></td><td>…</td><td><code>(kv_dim,)</code></td></tr></tbody></table><h2 id="tokenizer文件"><a href="#tokenizer文件" class="headerlink" title="tokenizer文件"></a><code>tokenizer</code>文件</h2><p>该文件结构与之前版本有差异，文件开头增加了一个4字节的<code>int</code>值<code>max_token_length</code>，统计了所有token最大的长度。其次是遍历每个token的内容，包括新增的一个<code>float</code>的<code>vocab_scores</code>，然后是4个字节<code>int</code>型的token长度，紧接着是token内容（不包括结束符的字符串），所有token一个挨一个存储。内存结构示意图如下。</p><blockquote><p><code>vocab_size</code> 存储在 <code>checkpoint</code> 文件里。</p></blockquote><table><thead><tr><th>文件头</th><th>token-0</th><th></th><th></th><th>token-1</th><th></th><th></th><th>…</th><th>token-n</th><th></th><th></th></tr></thead><tbody><tr><td>max_token_length</td><td>vocab_scores</td><td>token len</td><td>token content</td><td>vocab_scores</td><td>token len</td><td>token content</td><td>…</td><td>vocab_scores</td><td>token len</td><td>token content</td></tr><tr><td>27</td><td>0.0</td><td>1</td><td>l</td><td>0.0</td><td>4</td><td>like</td><td>…</td><td>0.0</td><td>11</td><td>suggestions</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><code>MQA</code>、<code>GQA</code>是最近出现的技术，原本的注意力机制是<code>Multi-Head Attention(MHA)</code>，每个query head对应一个key、value的head，最简化的情况是<code>MQA</code>，所有query head共享一组key、value head，$W_k$和$W_v$矩阵维度缩小为原来的<code>1/n_heads</code>，内存占用和推理速度提升非常明显，但相应的性能下降了（每个token对应的维度也变为原来的<code>1/n_heads</code>，信息被严重压缩）。折中的方案就是<code>GQA</code>，处于两者中间，且可以配置<code>n_kv_heads</code>大小，自由权衡取舍。</p><blockquote><p>GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints</p><footer><strong>Joshua Ainslie</strong><cite><a href="https://arxiv.org/abs/2305.13245v1">GQA</a></cite></footer></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;与早期版本（详情可以参考这里：&lt;a href=&quot;/2024/04/17/Dive-into-Transformer-simpliest-implementation-llama2-c-4e23ad8/&quot; title=&quot;极简&amp;#96;Transformer&amp;#96;实现(基于</summary>
      
    
    
    
    <category term="AI" scheme="https://waterdropw.github.io/categories/AI/"/>
    
    <category term="transformer" scheme="https://waterdropw.github.io/categories/AI/transformer/"/>
    
    <category term="self-attention" scheme="https://waterdropw.github.io/categories/AI/transformer/self-attention/"/>
    
    
    <category term="AI" scheme="https://waterdropw.github.io/tags/AI/"/>
    
    <category term="transformer" scheme="https://waterdropw.github.io/tags/transformer/"/>
    
    <category term="self-attention" scheme="https://waterdropw.github.io/tags/self-attention/"/>
    
  </entry>
  
  <entry>
    <title>多机多卡训练：NCCL Debug</title>
    <link href="https://waterdropw.github.io/2023/09/28/NCCL-Debug/"/>
    <id>https://waterdropw.github.io/2023/09/28/NCCL-Debug/</id>
    <published>2023-09-28T08:05:10.000Z</published>
    <updated>2025-11-20T11:56:58.958Z</updated>
    
    <content type="html"><![CDATA[<p>大模型因为参数量巨大，即使是Finetune也只能在多卡GPU的机器上训练（全精度），如果是A100 8卡40GB机器，用上DeepSpeed的各种优化之后勉强能训3B模型，7B模型训不了，必须要多机多卡才行。这里记录一下早期探索，使用裸机环境配置多机多卡来跑大模型训练遇到的一些问题。</p><p>多机多卡训练需要一个高效的通信框架来协调多个设备之间的数据传输和计算任务。常见的通信框架包括MPI、NCCL等。同时，多机多卡训练还需要一些额外的技术支持，如数据并行化、模型并行化等，以便将计算和存储任务分配到不同的设备上。</p><p>虽然多机多卡训练可以大大加速深度学习模型的训练速度，但也面临一些挑战，如设备故障、通信延迟等。因此，在应用多机多卡训练时需要谨慎选择合适的硬件设备和软件工具，并进行充分测试和优化。</p><span id="more"></span><h2 id="测试一"><a href="#测试一" class="headerlink" title="测试一"></a>测试一</h2><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>两台主机加入 swarm worker，docker 指定overlay network</p><p>容器启动之后，需要手动启动ssh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/ssh start</span><br></pre></td></tr></table></figure><p>运行 DeepSpeed-chat 多机训练</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NCCL_DEBUG_SUBSYS=ALL NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO python train.py --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type multi_node --actor-zero-stage 3 --output-dir /data/opt-1.3b-multi-node/ --hostfile hostfile</span><br></pre></td></tr></table></figure><h3 id="log-分析"><a href="#log-分析" class="headerlink" title="log 分析"></a>log 分析</h3><p>错误如下：socket 连接错误</p><img src="/images/nccl/fig1.png" class="" width="1400" height="428" title="socket error"><p>GPU 不支持 NCCL IB，因此设置<code>NCCL_IB_DISABLE=1</code> 禁用掉，多机间通信将透过socket 建立连接，并且使用的eth0，eth1 是容器的网络配置</p><img src="/images/nccl/fig2.png" class="" width="865" height="188" title="NCCL IB"><p>容器内 ifconfig 结果：</p><img src="/images/nccl/fig3.png" class="" width="574" height="402" title="container ifconfig"><p>主机的ifconfig：</p><img src="/images/nccl/fig4.png" class="" width="593" height="600" title="host ifconfig"><p>如下提示，说明两个网络上 RDMA 也不能用</p><img src="/images/nccl/fig5.png" class="" width="813" height="34" title="RDMA"><img src="/images/nccl/fig6.png" class="" width="797" height="234" title="NCCL INFO"><img src="/images/nccl/fig7.png" class="" width="770" height="236" title="NCCL INFO"><h2 id="测试二"><a href="#测试二" class="headerlink" title="测试二"></a>测试二</h2><h3 id="环境配置-1"><a href="#环境配置-1" class="headerlink" title="环境配置"></a>环境配置</h3><p>两台主机未加入swarm（docker swarm leave），docker容器指定为host 网络，docker启动后ssh port 6000 修改为22</p><p>运行 DeepSpeed-chat 多机训练</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NCCL_DEBUG_SUBSYS=ALL NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO NCCL_SOCKET_IFNAME=eth0 python train.py --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type multi_node --actor-zero-stage 3 --output-dir /data/opt-1.3b-multi-node/ --hostfile hostfile</span><br></pre></td></tr></table></figure><h3 id="log-分析-1"><a href="#log-分析-1" class="headerlink" title="log 分析"></a>log 分析</h3><img src="/images/nccl/fig8.png" class="" width="1358" height="449" title="socket error"><img src="/images/nccl/fig8.png" class="" width="1247" height="26" title="socket error"><img src="/images/nccl/fig8.png" class="" width="1360" height="71" title="socket error"><img src="/images/nccl/fig8.png" class="" width="1121" height="63" title="socket error"><h2 id="测试三"><a href="#测试三" class="headerlink" title="测试三"></a>测试三</h2><h3 id="环境配置-2"><a href="#环境配置-2" class="headerlink" title="环境配置"></a>环境配置</h3><p>两台主机未加入swarm（docker swarm leave），docker容器指定为host 网络，docker启动后ssh port 6000 修改为22</p><p>torchrun 运行 BELLE&#x2F;train 多机训练，排除DeepSpeed的影响</p><p>node1 （182）上执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OMP_NUM_THREADS=8 torchrun --node_rank=0 --master_addr=192.168.0.8 --master_port=29500 --nnodes=2 --nproc_per_node=8 finetune.py --model_config_file run_config/Bloom_config.json --lora_hyperparams_file run_config/lora_hyperparams_bloom.json --use_lora</span><br></pre></td></tr></table></figure><p>node2 （188）上执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OMP_NUM_THREADS=8 torchrun --node_rank=1 --master_addr=192.168.0.16 --master_port=29500 --nnodes=2 --nproc_per_node=8 finetune.py --model_config_file run_config/Bloom_config.json --lora_hyperparams_file run_config/lora_hyperparams_bloom.json --use_lora</span><br></pre></td></tr></table></figure><h2 id="测试四"><a href="#测试四" class="headerlink" title="测试四"></a>测试四</h2><h3 id="环境配置-3"><a href="#环境配置-3" class="headerlink" title="环境配置"></a>环境配置</h3><p>两台主机未加入swarm（docker swarm leave），docker容器指定为host 网络，docker启动后ssh port 6000 修改为22</p><p>运行 nccl test 命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NCCL_DEBUG_SUBSYS=ALL NCCL_DEBUG=INFO NCCL_IB_DISABLE=1 NCCL_SOCKET_IFNAME=eth0 mpirun --allow-run-as-root  -np 16 -H 192.168.0.8:54321,192.168.0.16:54321 ./build/all_gather_perf  -b 8 -e  128M -f 2 -g 8 2&gt;&amp;1 |<span class="built_in">tee</span> ib.log</span><br></pre></td></tr></table></figure><h2 id="最终解决方案"><a href="#最终解决方案" class="headerlink" title="最终解决方案"></a>最终解决方案</h2><p>分析 nccl_test log发现，多机之间的连接还是因为防火墙和iptables 的影响，索性关闭防火墙</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">iptables -t nat -P PREROUTING ACCEPT</span><br><span class="line">iptables -t nat -P POSTROUTING ACCEPT</span><br><span class="line">iptables -t nat -P OUTPUT ACCEPT</span><br><span class="line">iptables -t nat -F</span><br><span class="line">iptables -t nat -X</span><br><span class="line">iptables -t mangle -P PREROUTING ACCEPT</span><br><span class="line">iptables -t mangle -P INPUT ACCEPT</span><br><span class="line">iptables -t mangle -P FORWARD ACCEPT</span><br><span class="line">iptables -t mangle -P OUTPUT ACCEPT</span><br><span class="line">iptables -t mangle -P POSTROUTING ACCEPT</span><br><span class="line">iptables -t mangle -F</span><br><span class="line">iptables -t mangle -X</span><br><span class="line">iptables -t filter -P INPUT ACCEPT</span><br><span class="line">iptables -t filter -P FORWARD ACCEPT</span><br><span class="line">iptables -t filter -P OUTPUT ACCEPT</span><br><span class="line">iptables -t filter -F</span><br><span class="line">iptables -t filter -X</span><br><span class="line"></span><br><span class="line">ufw <span class="built_in">disable</span></span><br></pre></td></tr></table></figure><p>双机训练跑通，中途worker的ssh 连接中断了，稳定性有待验证</p><details>  <summary>点击展开</summary>  <pre><code>[2023-04-17 17:13:37,910] [INFO] [runner.py:446:main] Using IP address of 192.168.0.8 for node a182[2023-04-17 17:13:37,911] [INFO] [multinode_runner.py:70:get_cmd] Running on the following workers: a182,a188[2023-04-17 17:13:37,911] [INFO] [runner.py:540:main] cmd = pdsh -S -f 1024 -w a182,a188 export NCCL_VERSION=2.16.5; export NCCL_SOCKET_IFNAME=eth0; export PYTHONIOENCODING=utf-8; export NCCL_IB_DISABLE=1; export PYTHONPATH=/data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning;  cd /data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning; /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJhMTgyIjogWzAsIDEsIDIsIDMsIDQsIDUsIDYsIDddLCAiYTE4OCI6IFswLCAxLCAyLCAzLCA0LCA1LCA2LCA3XX0= --node_rank=%n --master_addr=192.168.0.8 --master_port=29500 main.py --data_path 'Dahoas/rm-static' 'Dahoas/full-hh-rlhf' 'Dahoas/synthetic-instruct-gptj-pairwise' 'yitingxie/rlhf-reward-datasets' 'openai/webgpt_comparisons' 'stanfordnlp/SHP' --data_split '2,4,4' --model_name_or_path 'facebook/opt-1.3b' --per_device_train_batch_size '4' --per_device_eval_batch_size '4' --max_seq_len '512' --learning_rate '1e-4' --weight_decay '0.1' --num_train_epochs '2' --gradient_accumulation_steps '1' --lr_scheduler_type 'cosine' --num_warmup_steps '0' --seed '1234' --gradient_checkpointing --zero_stage '3' --lora_dim '128' --lora_module_name 'decoder.layers.' --deepspeed --output_dir '/data/opt-1.3b-multi-node/actor-models/1.3b'a182: [2023-04-17 17:13:43,896] [INFO] [launch.py:222:main] 0 NCCL_VERSION=2.16.5a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:222:main] 0 NCCL_SOCKET_IFNAME=eth0a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:222:main] 0 NCCL_IB_DISABLE=1a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:229:main] WORLD INFO DICT: &#123;'a182': [0, 1, 2, 3, 4, 5, 6, 7], 'a188': [0, 1, 2, 3, 4, 5, 6, 7]&#125;a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:235:main] nnodes=2, num_local_procs=8, node_rank=0a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, &#123;'a182': [0, 1, 2, 3, 4, 5, 6, 7], 'a188': [8, 9, 10, 11, 12, 13, 14, 15]&#125;)a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:247:main] dist_world_size=16a182: [2023-04-17 17:13:43,897] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:222:main] 1 NCCL_VERSION=2.16.5a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:222:main] 1 NCCL_SOCKET_IFNAME=eth0a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:222:main] 1 NCCL_IB_DISABLE=1a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:229:main] WORLD INFO DICT: &#123;'a182': [0, 1, 2, 3, 4, 5, 6, 7], 'a188': [0, 1, 2, 3, 4, 5, 6, 7]&#125;a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:235:main] nnodes=2, num_local_procs=8, node_rank=1a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, &#123;'a182': [0, 1, 2, 3, 4, 5, 6, 7], 'a188': [8, 9, 10, 11, 12, 13, 14, 15]&#125;)a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:247:main] dist_world_size=16a188: [2023-04-17 17:13:43,896] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7a182: [2023-04-17 17:13:54,469] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccla182: 'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /facebook/opt-1.3b/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f214c1f8f70>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/facebook/opt-1.3b/resolve/main/config.jsona182: [2023-04-17 17:17:31,616] [INFO] [partition_parameters.py:436:__exit__] finished initializing model with 1.42B parametersa188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  1.16it/s]100%|██████████| 2/2 [00:00<00:00,  2.09it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.89it/s] 50%|█████     | 1/2 [00:01<00:01,  1.10s/it]100%|██████████| 2/2 [00:01<00:00,  1.94it/s]100%|██████████| 2/2 [00:00<00:00,  5.87it/s]100%|██████████| 2/2 [00:00<00:00,  5.45it/s]a182:100%|██████████| 2/2 [00:01<00:00,  1.66it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 443.23it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 491.34it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 511.10it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 476.49it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 398.15it/s]a182: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a182:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 328.45it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 408.01it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 438.39it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 476.30it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 477.85it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 315.48it/s]a188: Found cached dataset parquet (/root/.cache/huggingface/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)a188:  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 450.35it/s]a188: Traceback (most recent call last):a188:   File "main.py", line 339, in <module>a188:     main()a188:   File "main.py", line 218, in maina188:     train_dataset, eval_dataset = create_prompt_dataset(a188:   File "/data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/data/data_utils.py", line 279, in create_prompt_dataseta188:     train_dataset, eval_dataset = create_dataset(a188:   File "/data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/data/data_utils.py", line 212, in create_dataseta188:     raw_dataset = get_raw_dataset(dataset_name, output_path, seed, local_rank)a188:   File "/data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/data/data_utils.py", line 21, in get_raw_dataseta188:     return raw_datasets.DahoasRmstaticDataset(output_path, seed,a188:   File "/data/repos/DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/data/raw_datasets.py", line 52, in __init__a188:     self.raw_datasets = load_dataset("Dahoas/rm-static")a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1767, in load_dataseta188:     builder_instance = load_dataset_builder(a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1498, in load_dataset_buildera188:     dataset_module = dataset_module_factory(a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1215, in dataset_module_factorya188:     raise e1 from Nonea188:   File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1192, in dataset_module_factorya188:     return HubDatasetModuleFactoryWithoutScript(a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 825, in get_modulea188:     dataset_readme_path = cached_path(a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/utils/file_utils.py", line 183, in cached_patha188:     output_path = get_from_cache(a188:   File "/usr/local/lib/python3.8/dist-packages/datasets/utils/file_utils.py", line 566, in get_from_cachea188:     raise ConnectionError(f"Couldn't reach &#123;url&#125; (&#123;repr(head_error)&#125;)")a188: ConnectionError: Couldn't reach https://huggingface.co/datasets/Dahoas/rm-static/resolve/main/README.md (ReadTimeout(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=100)")))a188: [2023-04-17 18:19:46,372] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9324a188: [2023-04-17 18:19:46,591] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9325a188: [2023-04-17 18:19:46,806] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9326a188: [2023-04-17 18:19:46,980] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9327a188: [2023-04-17 18:19:47,195] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9328a188: [2023-04-17 18:19:47,369] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9329a188: [2023-04-17 18:19:47,542] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9330a188: [2023-04-17 18:19:47,543] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 9332a188: [2023-04-17 18:19:47,917] [ERROR] [launch.py:434:sigkill_handler] ['/usr/bin/python', '-u', 'main.py', '--local_rank=7', '--data_path', 'Dahoas/rm-static', 'Dahoas/full-hh-rlhf', 'Dahoas/synthetic-instruct-gptj-pairwise', 'yitingxie/rlhf-reward-datasets', 'openai/webgpt_comparisons', 'stanfordnlp/SHP', '--data_split', '2,4,4', '--model_name_or_path', 'facebook/opt-1.3b', '--per_device_train_batch_size', '4', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-4', '--weight_decay', '0.1', '--num_train_epochs', '2', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--num_warmup_steps', '0', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '3', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--output_dir', '/data/opt-1.3b-multi-node/actor-models/1.3b'] exits with return code = 1pdsh@ecs-21075649-010: a188: ssh exited with exit code 1pdsh@ecs-21075649-010: interrupt (one more within 1 sec to abort)pdsh@ecs-21075649-010:  (^Z within 1 sec to cancel pending threads)pdsh@ecs-21075649-010: a182: command in progresssending SIGTERM to ssh a182sending signal 15 to a182 [ssh] pid 5758pdsh@ecs-21075649-010: interrupt, aborting.pdsh@ecs-21075649-010: a188: ssh exited with exit code 1  </code></pre></details><h2 id="性能对比测试"><a href="#性能对比测试" class="headerlink" title="性能对比测试"></a>性能对比测试</h2><h3 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h3><p>4x A100 8卡 A100-PCIE-40GB</p><p>【step1】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">deepspeed --hostfile=<span class="variable">$HOSTFILE</span> main.py \</span><br><span class="line">   --data_path all_instruction_data_for_DeepSpeedChat \</span><br><span class="line">   --data_split 2,4,4 \</span><br><span class="line">   --model_name_or_path /data/models/bigscience_bloomz-7b1 \</span><br><span class="line">   --per_device_train_batch_size 4 \</span><br><span class="line">   --per_device_eval_batch_size 4 \</span><br><span class="line">   --max_seq_len 2048 \</span><br><span class="line">   --learning_rate 1e-4 \</span><br><span class="line">   --weight_decay 0.1 \</span><br><span class="line">   --num_train_epochs 2  \</span><br><span class="line">   --gradient_accumulation_steps 1 \</span><br><span class="line">   --lr_scheduler_type cosine \</span><br><span class="line">   --num_warmup_steps 0 \</span><br><span class="line">   --seed 1234 \</span><br><span class="line">   --gradient_checkpointing \</span><br><span class="line">   --zero_stage <span class="variable">$ZERO_STAGE</span> \</span><br><span class="line">   --lora_dim 128 \</span><br><span class="line">   --lora_module_name decoder.layers. \</span><br><span class="line">   --deepspeed \</span><br><span class="line">   --output_dir <span class="variable">$OUTPUT</span> \</span><br><span class="line">   &amp;&gt; <span class="variable">$OUTPUT</span>/training.log</span><br></pre></td></tr></table></figure><p>【step3】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">deepspeed --hostfile=<span class="variable">$HOSTFILE</span> --master_port 12346 main.py \</span><br><span class="line">   --data_path all_instruction_data_for_DeepSpeedChat \</span><br><span class="line">   --data_split 2,4,4 \</span><br><span class="line">   --actor_model_name_or_path <span class="variable">$ACTOR_MODEL_PATH</span> \</span><br><span class="line">   --critic_model_name_or_path <span class="variable">$CRITIC_MODEL_PATH</span> \</span><br><span class="line">   --num_padding_at_beginning 1 \</span><br><span class="line">   --per_device_train_batch_size 4 \</span><br><span class="line">   --per_device_mini_train_batch_size 4 \</span><br><span class="line">   --generation_batch_numbers 1 \</span><br><span class="line">   --ppo_epochs 1 \</span><br><span class="line">   --max_answer_seq_len 1024 \</span><br><span class="line">   --max_prompt_seq_len 1024 \</span><br><span class="line">   --actor_learning_rate <span class="variable">$&#123;Actor_Lr&#125;</span> \</span><br><span class="line">   --critic_learning_rate <span class="variable">$&#123;Critic_Lr&#125;</span> \</span><br><span class="line">   --actor_weight_decay 0.1 \</span><br><span class="line">   --critic_weight_decay 0.1 \</span><br><span class="line">   --num_train_epochs 1 \</span><br><span class="line">   --lr_scheduler_type cosine \</span><br><span class="line">   --gradient_accumulation_steps 1 \</span><br><span class="line">   --num_warmup_steps 100 \</span><br><span class="line">   --deepspeed --seed 1234 \</span><br><span class="line">   --enable_hybrid_engine \</span><br><span class="line">   --inference_tp_size 8 \</span><br><span class="line">   --tp_gather_partition_size 4 \</span><br><span class="line">   --actor_zero_stage <span class="variable">$ACTOR_ZERO_STAGE</span> \</span><br><span class="line">   --critic_zero_stage <span class="variable">$CRITIC_ZERO_STAGE</span> \</span><br><span class="line">   --actor_gradient_checkpointing \</span><br><span class="line">   --actor_lora_dim 128 \</span><br><span class="line">   --actor_lora_module_name decoder.layers. \</span><br><span class="line">   --output_dir <span class="variable">$OUTPUT</span> \</span><br><span class="line">    &amp;&gt; <span class="variable">$OUTPUT</span>/training.log</span><br></pre></td></tr></table></figure><p>【training.log】</p><details>  <summary>点击展开</summary>  <pre><code>a182: ***** Running training *****a182: ***** Evaluating perplexity, Epoch 0/2 *****a182: ppl: 1615.3291015625a182: Beginning of Epoch 1/2, Total Micro Batches 844a182: [2023-04-21 15:32:05,774] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1a182: [2023-04-21 15:32:47,044] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768a182: [2023-04-21 15:33:29,700] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384a182: [2023-04-21 15:34:11,199] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192a182: [2023-04-21 15:34:53,648] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096a182: [2023-04-21 15:35:37,038] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048a182: [2023-04-21 15:36:19,724] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, reducing to 1024a182: [2023-04-21 15:37:02,075] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024, reducing to 512a182: [2023-04-21 15:37:44,410] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 512, reducing to 256a182: [2023-04-21 15:38:26,336] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 128a182: [2023-04-21 15:38:26,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0001, 0.0001], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-21 15:38:26,338] [INFO] [timer.py:199:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=3.018237674524317, CurrSamplesPerSec=3.0533144699669323, MemAllocated=8.18GB, MaxMemAllocated=27.21GBa182: [2023-04-21 15:39:09,043] [WARNING] [stage3.py:1787:step] 17 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:39:50,772] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:40:32,341] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:41:14,049] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:41:55,981] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:42:38,949] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:44:05,257] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:44:47,426] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:45:29,589] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:45:29,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=10, lr=[9.999134070902207e-05, 9.999134070902207e-05], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-21 15:45:29,591] [INFO] [timer.py:199:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=3.021699438930297, CurrSamplesPerSec=3.0359636074270875, MemAllocated=8.18GB, MaxMemAllocated=27.21GBa182: [2023-04-21 15:46:10,884] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:46:53,122] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:47:34,534] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:48:16,075] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:48:58,285] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:49:40,420] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:50:23,103] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:51:06,003] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:51:47,326] [WARNING] [stage3.py:1787:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:52:29,013] [WARNING] [stage3.py:1787:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-21 15:52:29,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=10, lr=[9.996536583542105e-05, 9.996536583542105e-05], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-21 15:52:29,015] [INFO] [timer.py:199:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=3.0324580151109792, CurrSamplesPerSec=3.0706646549224987, MemAllocated=8.18GB, MaxMemAllocated=27.21GB  </code></pre></details><p>【GPU Loading】</p><img src="/images/nccl/fig12.png" class="" width="400" height="444" title="nvidia-smi"><p>【内存占用】</p><img src="/images/nccl/fig13.png" class="" width="960" height="540" title="htop"><h3 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h3><p>6x A100 8卡 A100-PCIE-40GB<br>训练参数与实验1完全相同，只是增加了两台机器</p><p>【结论】：还是会有显存高压的警告，不过没有连续出现。担心step3 还是会爆掉。先跑完step1，后面可以单独跑step2,3</p><p>【training.log】</p><details>  <summary>点击展开</summary>  <pre><code>a182: Time to load utils op: 0.0005230903625488281 secondsa182: ***** Running training *****a182: ***** Evaluating perplexity, Epoch 0/2 *****a182: ppl: 1615.9046630859375a182: Beginning of Epoch 1/2, Total Micro Batches 563a182: [2023-04-22 00:20:37,845] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1a182: [2023-04-22 00:21:23,520] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768a182: [2023-04-22 00:22:08,163] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384a182: [2023-04-22 00:22:54,065] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192a182: [2023-04-22 00:23:40,058] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096a182: [2023-04-22 00:24:25,473] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048a182: [2023-04-22 00:25:12,089] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, reducing to 1024a182: [2023-04-22 00:25:58,308] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024, reducing to 512a182: [2023-04-22 00:26:43,708] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 512, reducing to 256a182: [2023-04-22 00:27:30,709] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 128a182: [2023-04-22 00:27:30,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0001, 0.0001], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-22 00:27:30,712] [INFO] [timer.py:199:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=4.183477766906136, CurrSamplesPerSec=4.0852692074479595, MemAllocated=7.04GB, MaxMemAllocated=26.07GBa182: [2023-04-22 00:28:17,487] [WARNING] [stage3.py:1787:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same timea182: [2023-04-22 00:35:01,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=10, lr=[9.99805403600595e-05, 9.99805403600595e-05], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-22 00:35:01,688] [INFO] [timer.py:199:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=4.224439829942313, CurrSamplesPerSec=4.238250039396783, MemAllocated=7.04GB, MaxMemAllocated=26.07GBa182: [2023-04-22 00:42:17,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=10, lr=[9.99221765873415e-05, 9.99221765873415e-05], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-22 00:42:17,327] [INFO] [timer.py:199:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=4.288112235651409, CurrSamplesPerSec=4.507034898076392, MemAllocated=7.04GB, MaxMemAllocated=26.07GBa182: [2023-04-22 00:49:22,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=10, lr=[9.982495411136606e-05, 9.982495411136606e-05], mom=[(0.9, 0.95), (0.9, 0.95)]a182: [2023-04-22 00:49:22,479] [INFO] [timer.py:199:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=4.345926499891864, CurrSamplesPerSec=4.512978428671682, MemAllocated=7.04GB, MaxMemAllocated=26.07GB  </code></pre></details><p>【GPU Loading】</p><img src="/images/nccl/fig14.png" class="" width="400" height="444" title="nvidia-smi"><p>【内存占用】</p><img src="/images/nccl/fig15.png" class="" width="960" height="540" title="htop">]]></content>
    
    
    <summary type="html">&lt;p&gt;大模型因为参数量巨大，即使是Finetune也只能在多卡GPU的机器上训练（全精度），如果是A100 8卡40GB机器，用上DeepSpeed的各种优化之后勉强能训3B模型，7B模型训不了，必须要多机多卡才行。这里记录一下早期探索，使用裸机环境配置多机多卡来跑大模型训练遇到的一些问题。&lt;/p&gt;
&lt;p&gt;多机多卡训练需要一个高效的通信框架来协调多个设备之间的数据传输和计算任务。常见的通信框架包括MPI、NCCL等。同时，多机多卡训练还需要一些额外的技术支持，如数据并行化、模型并行化等，以便将计算和存储任务分配到不同的设备上。&lt;/p&gt;
&lt;p&gt;虽然多机多卡训练可以大大加速深度学习模型的训练速度，但也面临一些挑战，如设备故障、通信延迟等。因此，在应用多机多卡训练时需要谨慎选择合适的硬件设备和软件工具，并进行充分测试和优化。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://waterdropw.github.io/categories/AI/"/>
    
    <category term="HPC" scheme="https://waterdropw.github.io/categories/AI/HPC/"/>
    
    <category term="GPU" scheme="https://waterdropw.github.io/categories/AI/HPC/GPU/"/>
    
    
    <category term="AI" scheme="https://waterdropw.github.io/tags/AI/"/>
    
    <category term="HPC" scheme="https://waterdropw.github.io/tags/HPC/"/>
    
    <category term="GPU" scheme="https://waterdropw.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>论文摘要-LLaMA</title>
    <link href="https://waterdropw.github.io/2023/09/28/LLaMA/"/>
    <id>https://waterdropw.github.io/2023/09/28/LLaMA/</id>
    <published>2023-09-28T06:48:11.000Z</published>
    <updated>2025-11-20T11:54:23.703Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient Foundation Language Models</a>，是一个包含了 7B ~ 65B 参数量的基础语言模型集合。并且<strong>仅仅在公开数据集</strong>上训练，T级别的数据量，可以达到Sota 水平。</p><p>对于要达到的模型性能，最好的模型并不是训练起来最快，而是推理起来要最快，这样才能节省部署成本。比起快速训练一个大模型，利用更长时间来训练一个小模型，能获得更好的推理性能。我们发现用 1T tokens 训练 7B 模型可以达到的性能，比用 200B tokens 训练一个 10B 的模型还要好。</p><p>这项工作的重点是使用更多的训练数据，在不同的推理预算内训练一系列模型，使其达到最佳性能，并且对比现有的 LLMs 的性能。比如 LLaMA-13B 在大多数benchmarks 测试中性能优于 GPT-3，而参数量减小了 10x 以上。LLaMA-65B 模型则可比肩目前最好的大模型如 Chinchilla、PaLM-540B。</p><span id="more"></span><h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><h3 id="预训练数据"><a href="#预训练数据" class="headerlink" title="预训练数据"></a>预训练数据</h3><p>预训练数据如下表：除了Wikipedia &amp; Books 用了2个epoch，其它都只用了1个epoch</p><img src="/images/llama/table1.png" class="" width="500" height="429" title="Pre-training data"><h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><p>与LLMs 一致，基于 transformer 来构建模型，并参考了后续模型的一些改进，主要有：</p><ol><li>Pre-nomalization 【GPT3】<br> 提升训练稳定性，使用 RMSNorm 函数归一化 sub-layer 的输入而不是输出 。</li><li>SwiGLU 激活函数【PaLM】<br> 使用 SwiGLU 代替 ReLU 以提升性能。</li><li>Rotary Embeddings【GPTNeo】<br> 使用 Rotary positional embeddings（RoPE）代替 absolute positional embeddings（APE）</li></ol><h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><p>使用 AdmW，beta1&#x3D;0.9, beta2&#x3D;0.95, warmup 2,000 steps</p><img src="/images/llama/table2.png" class="" width="807" height="238" title="Model Sizes"><h3 id="训练效率提升"><a href="#训练效率提升" class="headerlink" title="训练效率提升"></a>训练效率提升</h3><ol><li>causal multi-head attention 减少内存占用（xformers 实现）</li><li>反向过程中减少激活函数的重复计算，并且缓存了如线性层的激活结果，这得手动实现transformer layer 的反向传播代替Pytorch的autograd。</li><li>尽可能多的覆盖掉GPU之间的网络传输和激活函数计算（基于all_reduce算子）</li></ol><img src="/images/llama/fig1.png" class="" width="469" height="324" title="training performance"><h2 id="主要成果"><a href="#主要成果" class="headerlink" title="主要成果"></a>主要成果</h2><p>zero-shot : 输入任务描述和测试问题，模型输出生成的答案或对提议的答案进行排序。</p><p>few-shot（1, 64）：输入几个例子（1到64之间）和一个测试问题，模型输出生成的答案或对不同的选项进行排名。</p><h3 id="常识性推理"><a href="#常识性推理" class="headerlink" title="常识性推理"></a>常识性推理</h3><img src="/images/llama/table3.png" class="" width="954" height="424" title="Common Sense Reasoning"><h3 id="闭卷问答"><a href="#闭卷问答" class="headerlink" title="闭卷问答"></a>闭卷问答</h3><img src="/images/llama/table4.png" class="" width="487" height="430" title="NaturalQuestions"><img src="/images/llama/table5.png" class="" width="487" height="324" title="TriviaQA"><h3 id="阅读理解"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解</h3><img src="/images/llama/table6.png" class="" width="491" height="392" title="Reading Comprehension"><h3 id="数学推理"><a href="#数学推理" class="headerlink" title="数学推理"></a>数学推理</h3><img src="/images/llama/table7.png" class="" width="482" height="584" title="MATH &amp; GSM"><h3 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h3><img src="/images/llama/table8.png" class="" width="484" height="540" title="Code Generation"><h3 id="大规模多任务语言理解"><a href="#大规模多任务语言理解" class="headerlink" title="大规模多任务语言理解"></a>大规模多任务语言理解</h3><img src="/images/llama/table9.png" class="" width="801" height="464" title="Massive Multitask Language Understanding">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2302.13971&quot;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;，是一个包含了 7B ~ 65B 参数量的基础语言模型集合。并且&lt;strong&gt;仅仅在公开数据集&lt;/strong&gt;上训练，T级别的数据量，可以达到Sota 水平。&lt;/p&gt;
&lt;p&gt;对于要达到的模型性能，最好的模型并不是训练起来最快，而是推理起来要最快，这样才能节省部署成本。比起快速训练一个大模型，利用更长时间来训练一个小模型，能获得更好的推理性能。我们发现用 1T tokens 训练 7B 模型可以达到的性能，比用 200B tokens 训练一个 10B 的模型还要好。&lt;/p&gt;
&lt;p&gt;这项工作的重点是使用更多的训练数据，在不同的推理预算内训练一系列模型，使其达到最佳性能，并且对比现有的 LLMs 的性能。比如 LLaMA-13B 在大多数benchmarks 测试中性能优于 GPT-3，而参数量减小了 10x 以上。LLaMA-65B 模型则可比肩目前最好的大模型如 Chinchilla、PaLM-540B。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://waterdropw.github.io/categories/AI/"/>
    
    <category term="LLM" scheme="https://waterdropw.github.io/categories/AI/LLM/"/>
    
    <category term="LlaMa" scheme="https://waterdropw.github.io/categories/AI/LLM/LlaMa/"/>
    
    
    <category term="AI" scheme="https://waterdropw.github.io/tags/AI/"/>
    
    <category term="LLM" scheme="https://waterdropw.github.io/tags/LLM/"/>
    
    <category term="LlaMa" scheme="https://waterdropw.github.io/tags/LlaMa/"/>
    
  </entry>
  
  <entry>
    <title>C++ 函数实现的异常覆盖</title>
    <link href="https://waterdropw.github.io/2020/12/25/Compiler-Bug-for-C-Funcs-Override/"/>
    <id>https://waterdropw.github.io/2020/12/25/Compiler-Bug-for-C-Funcs-Override/</id>
    <published>2020-12-25T10:09:59.000Z</published>
    <updated>2025-11-20T11:53:30.500Z</updated>
    
    <content type="html"><![CDATA[<p><code>Android NDK</code> 有一些巨坑，编译链接没什么问题，运行时出错，而且非常难查。比如<strong>声明有返回值的函数实现漏写<code>return</code>语句</strong>， 会导致函数调用之后跑飞，<code>x86</code>不会有问题。最近遇到另外一个巨坑，采用静态链接第三方库，如果有同名函数，即使是函数签名不同，函数实现会被覆盖，也就是调用到的是第三方库实现，本地实现被覆盖掉, OMG~~~~</p><span id="more"></span><p>编译环境：<br><strong>Host</strong>： MacOS<br><strong>Target</strong>: Android NDKr20<br><strong>ToolChain</strong>: bazel<br><strong>Link</strong>: Static Library</p><p>动态链接会报同名函数重定义错误~~ 该问题仅限于<strong>静态链接</strong></p><p>本地函数声明如下，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">namespace</span> libfcc &#123;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">LIBFCC_API</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">I420ToNV12</span><span class="params">(<span class="type">const</span> u8 *src_i420, u8 *dst_nv12, <span class="type">int</span> width, <span class="type">int</span> height)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;  <span class="comment">// extern &quot;C&quot;</span></span><br><span class="line">&#125;  <span class="comment">// namespace libfcc</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>Google <code>libyuv</code> 同名函数声明如下，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">namespace</span> libyuv &#123;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">LIBYUV_API</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">I420ToNV12</span><span class="params">(<span class="type">const</span> <span class="type">uint8_t</span>* src_y,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> src_stride_y,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">const</span> <span class="type">uint8_t</span>* src_u,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> src_stride_u,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">const</span> <span class="type">uint8_t</span>* src_v,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> src_stride_v,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">uint8_t</span>* dst_y,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> dst_stride_y,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">uint8_t</span>* dst_uv,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> dst_stride_uv,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> width,</span></span></span><br><span class="line"><span class="params"><span class="function">               <span class="type">int</span> height)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;  <span class="comment">// extern &quot;C&quot;</span></span><br><span class="line">&#125;  <span class="comment">// namespace libyuv</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>然后，神奇发生了，只要测试代码里面调用了该同名函数，运行时莫名崩溃，百思不得其解。</p><p>代码实现里添加log 没有打印，因为是在 benchmark 测试里面调用，刚开始怀疑是 benchmark 屏蔽了 log 输出。抽出来 <code>main</code> 函数测试也有问题，意识到是函数实现被覆盖了，注释掉本地函数实现，依然编译链接通过，没有任何错误，确定是编译链接问题。移除 <code>libyuv</code> 库依赖，一切恢复正常！！</p><p>这里函数签名不同也能被覆盖，是比较坑的地方！原因是因为用了 <code>extern &quot;C&quot;</code> 声明，也就是不会做 mangling 处理，导致编译器无法识别不同的函数签名。这也是 C 无法实现函数重载的原因。</p><p>那为何没有报函数重定义错呢？！</p><p>因为我虽然带着 <code>libyuv</code> 编译了，但是本地代码里面没有任何地方引用到<code>libyuv</code>，也就是没有 include <code>libyuv</code> 头文件。所以，编译器把我本地头文件的函数声明，与<code>libyuv</code> 的函数实现编译到一起了，既有函数声明，又有函数定义，所以不会有编译错误。</p><p>那为何编译器没有报函数调用参数缺少的<code>Warning</code>?!</p><p>NDK 编译，静态链接下不会有 Warning！甚至于添加 <code>-Werror</code>，也不会有 build error 信息。Why？</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;Android NDK&lt;/code&gt; 有一些巨坑，编译链接没什么问题，运行时出错，而且非常难查。比如&lt;strong&gt;声明有返回值的函数实现漏写&lt;code&gt;return&lt;/code&gt;语句&lt;/strong&gt;， 会导致函数调用之后跑飞，&lt;code&gt;x86&lt;/code&gt;不会有问题。最近遇到另外一个巨坑，采用静态链接第三方库，如果有同名函数，即使是函数签名不同，函数实现会被覆盖，也就是调用到的是第三方库实现，本地实现被覆盖掉, OMG~~~~&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="NDK" scheme="https://waterdropw.github.io/categories/Android/NDK/"/>
    
    <category term="Compiler" scheme="https://waterdropw.github.io/categories/Android/NDK/Compiler/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="NDK" scheme="https://waterdropw.github.io/tags/NDK/"/>
    
    <category term="Compiler" scheme="https://waterdropw.github.io/tags/Compiler/"/>
    
  </entry>
  
  <entry>
    <title>Android Camera HAL 新架构</title>
    <link href="https://waterdropw.github.io/2020/11/18/Android-Camera-HAL-Treble/"/>
    <id>https://waterdropw.github.io/2020/11/18/Android-Camera-HAL-Treble/</id>
    <published>2020-11-18T09:40:24.000Z</published>
    <updated>2025-11-20T11:52:14.272Z</updated>
    
    <content type="html"><![CDATA[<p>我们也把 Camera 拆分成 <strong>三驾马车</strong> 来看：<code>App Framework</code>, <code>CameraService</code>, <code>Camera HAL</code></p><p>前面两个是 <code>Android AOSP</code> 代码，随着 Android 系统升级会持续更新，包含在 system.img 里面，同时 Java 部分接口也会包含在 <code>Android SDK</code> 一起发布。</p><p>随着 <code>Android 8.0</code> 的 Treble 架构发布，相当于是把三驾马车里面的前两架放到了 <code>system.img</code> 里面，一起随着 Android 系统升级更新，而最后一个则独立拆分出来，不仅仅是放到了新的进程里面，而且在手机系统上要求放到 <code>vendor</code> 分区，这样可以各自独立升级。</p><span id="more"></span><h1 id="三驾马车"><a href="#三驾马车" class="headerlink" title="三驾马车"></a>三驾马车</h1><p>先附上 Google 官方图例：</p><img src="/images/camera/ape_fwk_camera2.jpg" class="" width="749" height="596" title="Camera HAL 新架构"><p><code>App Framework</code> 部分是最上层部分，包括 Java &amp; C++ 代码，实现了 <code>Android Camera2 API</code> 接口，提供给 android 应用使用，Java 部分包含在 Android SDK 里面。</p><blockquote><p>source tree  </p></blockquote><ul><li>Java 实现：  <ul><li><a href="https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/java/android/hardware/">https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/java/android/hardware/</a></li><li><a href="https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/java/android/hardware/camera2">https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/java/android/hardware/camera2</a></li></ul></li><li>C++ 实现：  <ul><li><a href="https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/jni/">https://android.googlesource.com/platform/frameworks/base/+/refs/heads/master/core/jni/</a></li></ul></li></ul><p><code>CameraService</code> 是中间桥梁，负责沟通 Framework 与 Camera 硬件设备，把上层的调用需求透过 camera hal 接口转发给 HAL 硬件实现，同时返回处理结果。</p><blockquote><p>source tree  </p></blockquote><ul><li>C++ 实现：  <ul><li><a href="https://android.googlesource.com/platform/frameworks/av/+/refs/heads/master/camera/">https://android.googlesource.com/platform/frameworks/av/+/refs/heads/master/camera/</a>  </li><li><a href="https://android.googlesource.com/platform/frameworks/av/+/refs/heads/master/services/camera/libcameraservice/">https://android.googlesource.com/platform/frameworks/av/+/refs/heads/master/services/camera/libcameraservice/</a></li><li><a href="https://android.googlesource.com/platform/frameworks/hardware/interfaces/+/refs/heads/master/cameraservice/">https://android.googlesource.com/platform/frameworks/hardware/interfaces/+/refs/heads/master/cameraservice/</a></li></ul></li></ul><p><code>Camera HAL</code> 是硬件适配层，针对不同 camera 硬件模组，由 OEM 厂商提供具体实现</p><blockquote><p>source tree</p></blockquote><ul><li>Treble 架构  <ul><li><a href="https://android.googlesource.com/platform/hardware/interfaces/+/refs/heads/master/camera/">https://android.googlesource.com/platform/hardware/interfaces/+/refs/heads/master/camera/</a></li></ul></li><li>Legacy  <ul><li><a href="https://android.googlesource.com/platform/hardware/libhardware/+/refs/heads/master/modules/camera/">https://android.googlesource.com/platform/hardware/libhardware/+/refs/heads/master/modules/camera/</a></li></ul></li></ul><h1 id="第二架马车：cameraserver"><a href="#第二架马车：cameraserver" class="headerlink" title="第二架马车：cameraserver"></a>第二架马车：cameraserver</h1><p><code>frameworks/av/camera/cameraserver/main_cameraserver.cpp</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> LOG_TAG <span class="string">&quot;cameraserver&quot;</span></span></span><br><span class="line"><span class="comment">//#define LOG_NDEBUG 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CameraService.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hidl/HidlTransportSupport.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> android;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc __unused, <span class="type">char</span>** argv __unused)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">signal</span>(SIGPIPE, SIG_IGN);</span><br><span class="line">    <span class="comment">// Set 5 threads for HIDL calls. Now cameraserver will serve HIDL calls in</span></span><br><span class="line">    <span class="comment">// addition to consuming them from the Camera HAL as well.</span></span><br><span class="line">    hardware::<span class="built_in">configureRpcThreadpool</span>(<span class="number">5</span>, <span class="comment">/*willjoin*/</span> <span class="literal">false</span>);</span><br><span class="line">    <span class="function">sp&lt;ProcessState&gt; <span class="title">proc</span><span class="params">(ProcessState::self())</span></span>;</span><br><span class="line">    sp&lt;IServiceManager&gt; sm = <span class="built_in">defaultServiceManager</span>();</span><br><span class="line">    <span class="built_in">ALOGI</span>(<span class="string">&quot;ServiceManager: %p&quot;</span>, sm.<span class="built_in">get</span>());</span><br><span class="line">    CameraService::<span class="built_in">instantiate</span>();</span><br><span class="line">    <span class="built_in">ALOGI</span>(<span class="string">&quot;ServiceManager: %p done instantiate&quot;</span>, sm.<span class="built_in">get</span>());</span><br><span class="line">    ProcessState::<span class="built_in">self</span>()-&gt;<span class="built_in">startThreadPool</span>();</span><br><span class="line">    IPCThreadState::<span class="built_in">self</span>()-&gt;<span class="built_in">joinThreadPool</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>frameworks/av/camera/cameraserver/cameraserver.rc</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">service cameraserver /system/bin/cameraserver</span><br><span class="line">    class main</span><br><span class="line">    user cameraserver</span><br><span class="line">    group audio camera input drmrpc</span><br><span class="line">    ioprio rt 4</span><br><span class="line">    task_profiles CameraServiceCapacity MaxPerformance</span><br><span class="line">    rlimit rtprio 10 10</span><br></pre></td></tr></table></figure><h1 id="第三驾马车：HAL-Impl"><a href="#第三驾马车：HAL-Impl" class="headerlink" title="第三驾马车：HAL Impl"></a>第三驾马车：HAL Impl</h1><h2 id="Camera-Provider-实现"><a href="#Camera-Provider-实现" class="headerlink" title="Camera Provider 实现"></a>Camera Provider 实现</h2><p>首先，实现 hal 独立运行的进程，并向 <code>hwservicemanager</code> 注册 <code>ICameraProvider</code> 服务，对上层提供硬件功能，包括设备状态信息的查询&#x2F;更新，获取设备接口以便可以调用设备功能。</p><p>AOSP 代码目前有两个 <code>ICameraProvider</code> 服务进程：</p><ul><li><code>legacy/0</code>, 给内置相机用, 所以目前为止，Camera HALv3 实现还是属于<code>传统 HAL</code>，参考<a href="https://source.android.google.cn/devices/architecture/hal-types?hl=zh-cn">HAL 类型</a></li><li><code>external/0</code>, Android P 新增的调用外接 usb 相机的 HAL 服务进程</li></ul><p>它们都有对应的启动脚本，在系统启动时加载运行。所以<strong>内置相机</strong>和<strong>外接相机</strong>的HAL 实现是分别在两个不同进程里面，各自独立互不影响！</p><p>如果需要还可以扩展更多 camera provider，比如 <code>internal</code>, <code>legacy</code>, <code>external</code>, <code>remote</code> 等等，只要具备以下几个条件，<code>cameraservice</code> 就能透过 <code>CameraProviderManager</code> 查询到该服务并查询到 camera 设备列表，供 <code>App Framework</code> 使用该相机设备：</p><ul><li>启动脚本</li><li>启动 binary，调用 <code>defaultPassthroughServiceImplementation</code> 注册服务</li><li>manifest camera.provider 节点声明，包括 <code>ßtransport</code> 类型和 <code>instance</code> 实例节点名称</li></ul><p>进程启动时，会完成这么几件事，跟 <code>hwservicemanager</code>以及<code>PassthroughServiceManager</code>的交互通过 binder IPC 调用完成</p><ol><li>确保 <code>/dev/vndbinder</code> 对应的 binder 服务进程已经启动，如果没有则启动它</li><li>在该进程里透过 <code>android_dlopen_ext/dlopen</code> 加载对应版本的库，这里是<code>android.hardware.camera.provider@2.4-impl.so</code></li><li>透过 <code>dlsym</code> 获取到 <code>HIDL_FETCH_ICameraProvider</code> 方法，然后遍历 manifest 里面 <code>camera.provider</code> 这个 <code>hidl</code> 接口声明的 <code>instance</code> 实例名称，作为参数调用该方法， 即可获取到该实例对应的 <code>ICameraProvider</code> 实现</li><li>向 hwservicemanager 注册该服务：<ul><li>首先在 <code>hwservicemanager</code> 中插入一个 <code>HidlService</code> (interfaceName, instanceName)</li><li>其次生成的 <code>CameraProvider</code> 对象也要透过 IPC 调用 <code>hidl::manager::add</code> 把自己添加到 <code>hwservicemanager</code>，因为上一步已经插入了一个对应的 <code>HidlService</code> 所以仅仅是更新 <code>pid</code>和 <code>service</code> 指向实例对象</li><li>(interfaceName， instanceName) 对应 internal camera provider 就是 (“<a href="mailto:&#x61;&#110;&#x64;&#x72;&#x6f;&#105;&#x64;&#x2e;&#104;&#97;&#114;&#x64;&#x77;&#x61;&#x72;&#101;&#46;&#99;&#97;&#x6d;&#x65;&#114;&#97;&#46;&#112;&#x72;&#x6f;&#118;&#x69;&#x64;&#101;&#x72;&#x40;&#x32;&#x2e;&#52;">&#x61;&#110;&#x64;&#x72;&#x6f;&#105;&#x64;&#x2e;&#104;&#97;&#114;&#x64;&#x77;&#x61;&#x72;&#101;&#46;&#99;&#97;&#x6d;&#x65;&#114;&#97;&#46;&#112;&#x72;&#x6f;&#118;&#x69;&#x64;&#101;&#x72;&#x40;&#x32;&#x2e;&#52;</a>::ICameraProvider”, “&#x2F;legacy&#x2F;0”)，</li></ul></li></ol><p>这几个步骤都在当前启动的进程里面调用 <code>defaultPassthroughServiceImplementation</code> 完成的，所以调用过程中透过 <code>IPCThreadState::self()-&gt;getCallingPid()</code> 获取到当前进程的pid，也就是提供服务的进程。</p><p>详细代码可以跟踪该函数查阅，另外还要参考 <code>hardware/interfaces/camera</code> 源代码下面 <code>*.hal</code> 编译时由 <code>hidl-gen</code> 生成的中间源代码</p><img src="/images/camera/ICameraProvider-hal-gen.jpg" class="" width="364" height="419" title="hidl-gen intermediates"><p><code>HidlService</code> 保持的信息如下，包括<strong>接口名称</strong>, <strong>实例名称</strong>, <strong>实例对象</strong>， <strong>HAL进程pid</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">HidlService</span> &#123;</span><br><span class="line">    <span class="built_in">HidlService</span>(<span class="type">const</span> std::string &amp;interfaceName,</span><br><span class="line">                <span class="type">const</span> std::string &amp;instanceName,</span><br><span class="line">                <span class="type">const</span> sp&lt;IBase&gt; &amp;service,</span><br><span class="line">                <span class="type">const</span> <span class="type">pid_t</span> pid);</span><br><span class="line">    <span class="built_in">HidlService</span>(<span class="type">const</span> std::string &amp;interfaceName,</span><br><span class="line">                <span class="type">const</span> std::string &amp;instanceName)</span><br><span class="line">    : <span class="built_in">HidlService</span>(</span><br><span class="line">        interfaceName,</span><br><span class="line">        instanceName,</span><br><span class="line">        <span class="literal">nullptr</span>,</span><br><span class="line">        <span class="built_in">static_cast</span>&lt;<span class="type">pid_t</span>&gt;(IServiceManager::PidConstant::NO_PID))</span><br><span class="line">    &#123;&#125;</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">HidlService</span>() &#123;&#125;</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>这里可以看到，同一个 hidl 接口，可以有多个实例实现，对应不同类型的硬件设备，比如这里 <code>/legacy/0</code> 对应内置相机，<code>/external/0</code> 对应外接 usb 相机，它们的 <code>interfaceName</code> 一样，<code>instanceName</code> 不一样。并且各自有自己的独立进程。</p><p><code>camera.provider</code> 接口声明，包括 transport 是 <code>hwbinder</code>, 实例有两个 <code>legacy/0</code>, <code>external/0</code></p><p><code>manifest.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hal</span> <span class="attr">format</span>=<span class="string">&quot;hidl&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>android.hardware.camera.provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">transport</span>&gt;</span>hwbinder<span class="tag">&lt;/<span class="name">transport</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">interface</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ICameraProvider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">instance</span>&gt;</span>legacy/0<span class="tag">&lt;/<span class="name">instance</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">instance</span>&gt;</span>external/0<span class="tag">&lt;/<span class="name">instance</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">interface</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">fqname</span>&gt;</span>@2.4::ICameraProvider/legacy/0<span class="tag">&lt;/<span class="name">fqname</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">hal</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>hardware/interfaces/camera/provider/2.4/default/service.cpp</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">ALOGI</span>(<span class="string">&quot;CameraProvider@2.4 legacy service is starting.&quot;</span>);</span><br><span class="line">    <span class="comment">// The camera HAL may communicate to other vendor components via</span></span><br><span class="line">    <span class="comment">// /dev/vndbinder</span></span><br><span class="line">    android::ProcessState::<span class="built_in">initWithDriver</span>(<span class="string">&quot;/dev/vndbinder&quot;</span>);</span><br><span class="line">    <span class="type">status_t</span> status;</span><br><span class="line">    <span class="keyword">if</span> (kLazyService) &#123;</span><br><span class="line">        status = <span class="built_in">defaultLazyPassthroughServiceImplementation</span>&lt;ICameraProvider&gt;(<span class="string">&quot;legacy/0&quot;</span>,</span><br><span class="line">                                                                              <span class="comment">/*maxThreads*/</span> <span class="number">6</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        status = <span class="built_in">defaultPassthroughServiceImplementation</span>&lt;ICameraProvider&gt;(<span class="string">&quot;legacy/0&quot;</span>,</span><br><span class="line">                                                                          <span class="comment">/*maxThreads*/</span> <span class="number">6</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>hardware/interfaces/camera/provider/2.4/default/external-service.cpp</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">ALOGI</span>(<span class="string">&quot;External camera provider service is starting.&quot;</span>);</span><br><span class="line">    <span class="comment">// The camera HAL may communicate to other vendor components via</span></span><br><span class="line">    <span class="comment">// /dev/vndbinder</span></span><br><span class="line">    android::ProcessState::<span class="built_in">initWithDriver</span>(<span class="string">&quot;/dev/vndbinder&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">defaultPassthroughServiceImplementation</span>&lt;ICameraProvider&gt;(<span class="string">&quot;external/0&quot;</span>, <span class="comment">/*maxThreads*/</span> <span class="number">6</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意下面 <code>extern &quot;C&quot;</code> 的声明，确保 C++ 符合没有做 <strong>name mangling</strong> 处理，保持原样，确保服务进程启动时可以透过 <code>dlsym</code> 获取到 <strong>HIDL_FETCH_Interface</strong> 并构造服务实例对象，然后向<code>hwservicemanager</code>注册该服务。</p><p>同时 <code>CameraProvider</code> 类的实现是一个模板类工厂，根据不同模板参数创建对应的类实例。</p><p><code>hardware/interfaces/camera/provider/2.4/default/CameraProvider_2_4.cpp</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CameraProvider_2_4.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;LegacyCameraProviderImpl_2_4.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ExternalCameraProviderImpl_2_4.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *kLegacyProviderName = <span class="string">&quot;legacy/0&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *kExternalProviderName = <span class="string">&quot;external/0&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> android &#123;</span><br><span class="line"><span class="keyword">namespace</span> hardware &#123;</span><br><span class="line"><span class="keyword">namespace</span> camera &#123;</span><br><span class="line"><span class="keyword">namespace</span> provider &#123;</span><br><span class="line"><span class="keyword">namespace</span> V2_4 &#123;</span><br><span class="line"><span class="keyword">namespace</span> implementation &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> android::hardware:<span class="emoji" alias="camera" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f7.png?v8">&#x1f4f7;</span>:provider::V2_4::ICameraProvider;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">ICameraProvider* <span class="title">HIDL_FETCH_ICameraProvider</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> IMPL&gt;</span></span><br><span class="line"><span class="function">CameraProvider&lt;IMPL&gt;* <span class="title">getProviderImpl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    CameraProvider&lt;IMPL&gt; *provider = <span class="keyword">new</span> <span class="built_in">CameraProvider</span>&lt;IMPL&gt;();</span><br><span class="line">    <span class="keyword">if</span> (provider == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">ALOGE</span>(<span class="string">&quot;%s: cannot allocate camera provider!&quot;</span>, __FUNCTION__);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (provider-&gt;<span class="built_in">isInitFailed</span>()) &#123;</span><br><span class="line">        <span class="built_in">ALOGE</span>(<span class="string">&quot;%s: camera provider init failed!&quot;</span>, __FUNCTION__);</span><br><span class="line">        <span class="keyword">delete</span> provider;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> provider;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ICameraProvider* <span class="title">HIDL_FETCH_ICameraProvider</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> android::hardware:<span class="emoji" alias="camera" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f7.png?v8">&#x1f4f7;</span>:provider::V2_4::implementation;</span><br><span class="line">    ICameraProvider* provider = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">strcmp</span>(name, kLegacyProviderName) == <span class="number">0</span>) &#123;</span><br><span class="line">        provider = <span class="built_in">getProviderImpl</span>&lt;LegacyCameraProviderImpl_2_4&gt;();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">strcmp</span>(name, kExternalProviderName) == <span class="number">0</span>) &#123;</span><br><span class="line">        provider = <span class="built_in">getProviderImpl</span>&lt;ExternalCameraProviderImpl_2_4&gt;();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">ALOGE</span>(<span class="string">&quot;%s: unknown instance name: %s&quot;</span>, __FUNCTION__, name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> provider;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace implementation</span></span><br><span class="line">&#125;  <span class="comment">// namespace V2_4</span></span><br><span class="line">&#125;  <span class="comment">// namespace provider</span></span><br><span class="line">&#125;  <span class="comment">// namespace camera</span></span><br><span class="line">&#125;  <span class="comment">// namespace hardware</span></span><br><span class="line">&#125;  <span class="comment">// namespace android</span></span><br></pre></td></tr></table></figure><img src="/images/camera/android_camera_hal.svg" class="" width="514" height="953"><h1 id="自研-HAL-接入的方式"><a href="#自研-HAL-接入的方式" class="headerlink" title="自研 HAL 接入的方式"></a>自研 HAL 接入的方式</h1><img src="/images/camera/hal_ext.svg" class="" width="897" height="793"><p>To be continued…</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们也把 Camera 拆分成 &lt;strong&gt;三驾马车&lt;/strong&gt; 来看：&lt;code&gt;App Framework&lt;/code&gt;, &lt;code&gt;CameraService&lt;/code&gt;, &lt;code&gt;Camera HAL&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;前面两个是 &lt;code&gt;Android AOSP&lt;/code&gt; 代码，随着 Android 系统升级会持续更新，包含在 system.img 里面，同时 Java 部分接口也会包含在 &lt;code&gt;Android SDK&lt;/code&gt; 一起发布。&lt;/p&gt;
&lt;p&gt;随着 &lt;code&gt;Android 8.0&lt;/code&gt; 的 Treble 架构发布，相当于是把三驾马车里面的前两架放到了 &lt;code&gt;system.img&lt;/code&gt; 里面，一起随着 Android 系统升级更新，而最后一个则独立拆分出来，不仅仅是放到了新的进程里面，而且在手机系统上要求放到 &lt;code&gt;vendor&lt;/code&gt; 分区，这样可以各自独立升级。&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
  <entry>
    <title>Android 外接 USB 摄像头</title>
    <link href="https://waterdropw.github.io/2020/11/12/Android-External-USB-Cameras/"/>
    <id>https://waterdropw.github.io/2020/11/12/Android-External-USB-Cameras/</id>
    <published>2020-11-12T09:42:17.000Z</published>
    <updated>2025-11-20T11:52:25.666Z</updated>
    
    <content type="html"><![CDATA[<p>如前述文章所述，Google 在 Android P 上提供了对 usb camera 设备的支持，官方叫法是 <code>External USB Cameras</code> ，提供了完整 HALv3 实现并接入到 <code>CameraProviderManager</code>；可以让任何三方相机应用轻松调用到外接 USB 摄像头功能，而且使用方法跟内置相机几无差别，都是透过 <code>Android Camera API2</code> 调用。</p><p>遗憾的是该功能默认关闭，并且 OEM 厂商大概率也会去改 AOSP 代码，比如 multi-caemra，SAT 等功能的实现，有可能会对其造成影响。</p><p>这篇文章详述如何开启 Android 手机上原生支持 USB 外接摄像头这个功能。因为底层走 V4L2 接口，所以支持 UVC 驱动的视频设备都能支持，包括常见的单反，微单，PC 机用的 usb 摄像头，网络摄像头等等，应用非常广泛。</p><p>目前看网络上还没有这方面的相关资料，一些嵌入式设备可能有类似的功能实现 (基于 <code>Linux</code> 或 <code>Qt</code>)，基于 android 系统开发的也有可能是直接使用这套方案的。当然也可以实现自己的 HAL 模块并接入 Android Camera HAL 子系统，具体可参考这篇文章介绍 <a href="/2020/11/18/Android-Camera-HAL-Treble/" title="Android Camera HAL 新架构">Android Camera HAL 新架构</a></p><blockquote><p>提示：<br>需要 root 权限的手机，并且可以源码编译<br>如果都没有，退而求其次，备选方案可参考这篇文章 <a href="/2020/11/02/Android-USB-Camera-Implementations/" title="Android USB Camera 的实现方案">Android USB Camera 的实现方案</a></p></blockquote><span id="more"></span><p>首先确保手机系统支持 USB 主机模式 <code>android.hardware.usb.host</code>, 一个简单的办法是连接 usb 外设，然后安装运行<strong>USBEnumerator</strong> 这个 android demo app，看是否能列出连接的设备。</p><blockquote><p><strong>备注</strong><br><code>USBEnumerator</code> 获取方式：<br>Android Studio -&gt; Import an Android code sample -&gt; 搜索 USB -&gt; 编译安装</p></blockquote><p>当 Android 设备处于 USB 主机模式时，它会充当 USB 主机，为总线供电并枚举连接的 USB 设备。Android 3.1 及更高版本支持 USB 主机模式。</p><h1 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h1><h2 id="kernel-配置"><a href="#kernel-配置" class="headerlink" title="kernel 配置"></a>kernel 配置</h2><p>必须开启 kernel 对 UVC 设备的支持，主要是需要 V4L2 驱动层功能模块。<br>修改 kernel config 文件，增加如下声明</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">+CONFIG_USB_VIDEO_CLASS=y</span><br><span class="line">+CONFIG_MEDIA_USB_SUPPORT=y</span><br></pre></td></tr></table></figure><h2 id="android-配置"><a href="#android-配置" class="headerlink" title="android 配置"></a>android 配置</h2><p>external camera 默认是关闭的，需要修改配置脚本打开，以当前的 <code>2.4</code> 版本为例说明。</p><p><strong>第一步</strong>，修改产品对应的 product mk 配置文件，增加如下声明:</p><ul><li>第一行将 external-service 及其启动脚本加入系统</li><li>第二行是将新增加的 usb camera 配置文件拷贝到 out&#x2F;target&#x2F;product&#x2F;DEVICE&#x2F;vendor&#x2F;etc&#x2F; 下面，也可以省略这一步，直接 push 到手机。</li></ul><p><code>device/your_oem/your_product/product_xxx.mk</code></p><figure class="highlight mk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+PRODUCT_PACKAGES += android.hardware.camera.provider@2.4-external-service</span><br><span class="line"></span><br><span class="line">+PRODUCT_COPY_FILES += \</span><br><span class="line"><span class="section">+device/manufacturerX/productY/external_camera_config.xml:<span class="variable">$(TARGET_COPY_OUT_VENDOR)</span>/etc/external_camera_config.xml</span></span><br></pre></td></tr></table></figure><p>编译如下两个模块：</p><ul><li><code>hardware/interfaces/camera/provider/2.4</code></li><li><code>hardware/interfaces/camera/device/3.4</code></li></ul><p>然后 push 如下几个更新的库到手机 (<code>DEVICE</code> 换成对应的product)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># external provider</span></span><br><span class="line">adb push out/target/product/DEVICE/vendor/lib64/android.hardware.camera.provider@2.4-external.so /vendor/lib64/</span><br><span class="line">adb push out/target/product/DEVICE/vendor/lib/android.hardware.camera.provider@2.4-external.so /vendor/lib</span><br><span class="line"><span class="comment"># external camera device</span></span><br><span class="line">adb push out/target/product/DEVICE/vendor/lib64/camera.device@3.4-external-impl.so /vendor/lib64</span><br><span class="line">adb push out/target/product/DEVICE/vendor/lib/camera.device@3.4-external-impl.so /vendor/lib/</span><br><span class="line"><span class="comment"># external service</span></span><br><span class="line">adb push out/target/product/DEVICE/vendor/bin/hw/android.hardware.camera.provider@2.4-external-service /vendor/bin/hw/</span><br><span class="line"><span class="comment"># startup config</span></span><br><span class="line">adb push out/target/product/DEVICE/vendor/etc/init/android.hardware.camera.provider@2.4-external-service.rc /vendor/etc/init/</span><br></pre></td></tr></table></figure><p><strong>第二步</strong>， 在 ODM 或者 vendor manifest xml 里面，增加一个节点 <code>external/0</code>, hwservicemanager 会读取该配置信息，如果没有对应的节点信息，则无法注册 external HAL 服务，上层看不到 camera 设备。</p><p>source tree 位置: <code>device/VENDOR/DEVICE/[xxx_]manifest.xml</code><br>手机上位置：<code>/vendor/etc/vintf/manifest.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hal</span> <span class="attr">format</span>=<span class="string">&quot;hidl&quot;</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>android.hardware.camera.provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">transport</span> <span class="attr">arch</span>=<span class="string">&quot;32+64&quot;</span>&gt;</span>passthrough<span class="tag">&lt;/<span class="name">transport</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">impl</span> <span class="attr">level</span>=<span class="string">&quot;generic&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">impl</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">interface</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>ICameraProvider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">instance</span>&gt;</span>legacy/0<span class="tag">&lt;/<span class="name">instance</span>&gt;</span></span><br><span class="line">+       <span class="tag">&lt;<span class="name">instance</span>&gt;</span>external/0<span class="tag">&lt;/<span class="name">instance</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">interface</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">hal</span>&gt;</span></span><br></pre></td></tr></table></figure><p>直接更新手机上的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">adb pull /vendor/etc/vintf/manifest.xml ./</span><br><span class="line"><span class="comment"># 如上修改</span></span><br><span class="line">adb push manifest.xml /vendor/etc/vintf/</span><br></pre></td></tr></table></figure><p><strong>第三步</strong>，增加设备对应的 <code>external_camera_config.xml</code> 配置, 手动编辑好之后 push 到手机的 <code>/vendor/etc/</code> 下面即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adb push external_camera_config.xml /vendor/etc/</span><br></pre></td></tr></table></figure><p><code>/vendor/etc/external_camera_config.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;utf-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ExternalCamera</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Provider</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ignore</span>&gt;</span> <span class="comment">&lt;!-- Internal video devices to be ignored by external camera HAL --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>0<span class="tag">&lt;/<span class="name">id</span>&gt;</span> <span class="comment">&lt;!-- No leading/trailing spaces --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>1<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>32<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>33<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">ignore</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Provider</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- See ExternalCameraUtils.cpp for default values of Device configurations below --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Device</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Max JPEG buffer size in bytes--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">MaxJpegBufferSize</span> <span class="attr">bytes</span>=<span class="string">&quot;3145728&quot;</span>/&gt;</span> <span class="comment">&lt;!-- 3MB (~= 1080p YUV420) --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Size of v4l2 buffer queue when streaming &gt;= 30fps --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Larger value: more request can be cached pipeline (less janky)  --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Smaller value: use less memory --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">NumVideoBuffers</span> <span class="attr">count</span>=<span class="string">&quot;4&quot;</span>/&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Size of v4l2 buffer queue when streaming &lt; 30fps --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">NumStillBuffers</span> <span class="attr">count</span>=<span class="string">&quot;2&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- List of maximum fps for various output sizes --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Any image size smaller than the size listed in Limit row will report</span></span><br><span class="line"><span class="comment">            fps (as minimum frame duration) up to the fpsBound value. --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">FpsList</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- width/height must be increasing, fpsBound must be decreasing--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">Limit</span> <span class="attr">width</span>=<span class="string">&quot;640&quot;</span> <span class="attr">height</span>=<span class="string">&quot;480&quot;</span> <span class="attr">fpsBound</span>=<span class="string">&quot;30.0&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">Limit</span> <span class="attr">width</span>=<span class="string">&quot;1280&quot;</span> <span class="attr">height</span>=<span class="string">&quot;720&quot;</span> <span class="attr">fpsBound</span>=<span class="string">&quot;15.0&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">Limit</span> <span class="attr">width</span>=<span class="string">&quot;1920&quot;</span> <span class="attr">height</span>=<span class="string">&quot;1080&quot;</span> <span class="attr">fpsBound</span>=<span class="string">&quot;10.0&quot;</span>/&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- image size larger than the last entry will not be supported--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">FpsList</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Device</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ExternalCamera</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>第四步</strong>，可选（目前不需要），如果要支持 <code>Treble passthrough mode</code>，则需要更新 <code>sepolicy</code> 配置，以便 <code>camerserver</code> 可以访问 <code>UVC camera</code>  </p><p><code>device/VENDOR/DEVICE/sepolicy/xxx/hal_camera.te</code></p><figure class="highlight mk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+<span class="comment"># for external camera</span></span><br><span class="line">+allow cameraserver device:dir r_dir_perms;</span><br><span class="line">+allow cameraserver video_device:dir r_dir_perms;</span><br><span class="line">+allow cameraserver video_device:chr_file rw_file_perms;</span><br></pre></td></tr></table></figure><p>还有个简单直接的办法，调试时暂时关闭 <code>sepolicy</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0    <span class="comment"># 强制关闭 sepolicy</span></span><br></pre></td></tr></table></figure><h1 id="framework-修复"><a href="#framework-修复" class="headerlink" title="framework 修复"></a>framework 修复</h1><p>上述动态库和配置文件都 ready 之后，极大可能还会遇到 binder crash，JE 等各种崩溃，或者 App 看不到0，1 之外的其它摄像头设备，这是因为 OEM 厂商动了 AOSP 代码。不同的 OEM 修改不一样。</p><p>基本上都是改几行代码就能解决，主要是 <code>CameraManager.java</code> 这个文件! </p><h1 id="使用外接-usb-camera"><a href="#使用外接-usb-camera" class="headerlink" title="使用外接 usb camera"></a>使用外接 usb camera</h1><h2 id="Camera2Basic-预览"><a href="#Camera2Basic-预览" class="headerlink" title="Camera2Basic 预览"></a>Camera2Basic 预览</h2><p>编译安装 Camera2Basic 这个android demo app，手机连接 usb camera，打开app 界面，会看到有 <strong>“External JPEG(&#x2F;dev&#x2F;videox)”</strong> 这个设备，点击打开预览。</p><img src="/images/camera/Screenshot_2020-11-17-19-19-31-610_Camera2Basic.jpg" class="" width="270" height="560" title="相机列表"><p>如下是连接单反长焦镜头手机截图，从此单反的大光圈虚化，N 倍光学变焦手机也可以拥有！</p><img src="/images/camera/Screenshot_2020-11-26-18-42-17-619_Camera2Basic.jpg" class="" width="270" height="560" title="单反光学变焦"><img src="/images/camera/Screenshot_2020-11-26-18-42-40-228_Camera2Basic.jpg" class="" width="270" height="560" title="单反背景虚化"><blockquote><p><strong>备注</strong><br><code>Camera2Basic</code> 获取方式：<br>Android Studio -&gt; Import an Android code sample -&gt; Camera2Basic -&gt; 编译安装</p></blockquote><h2 id="微信视频通话"><a href="#微信视频通话" class="headerlink" title="微信视频通话"></a>微信视频通话</h2><p>微信默认使用前置摄像头（cameraId&#x3D;1），只需要让 external usb camera 返回给 CameraProviderManager 看到的 <code>cameraId</code> 是 “1” 即可。</p><blockquote><p>提示：  </p></blockquote><ul><li>external provider 调用 <code>cameraDeviceStatusChanged</code> 时返回 <code>cameraId=&quot;1&quot;</code>，确保 CameraProviderManager -&gt; cameraservice -&gt; App 看到的设备id 是 “1” ，替换掉前置。</li><li>external device 强制写死，比如 <code>mCameraId(&quot;/dev/video2&quot;)</code>, 确保 open&#x2F;close 时能正确打开 V4L2 设备节点</li><li>CameraProviderManager 需要修改，开机时已经检测并添加了 id&#x3D;1 的前置摄像头设备，因此它不会允许再添加 external usb 设备，这个逻辑需要修改一下。</li></ul><p>Enjoy yourself！！！</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><blockquote><p><code>Device Manifest</code><br><a href="https://source.android.com/devices/architecture/vintf/objects">https://source.android.com/devices/architecture/vintf/objects</a><br><code>External USB Cameras</code><br><a href="https://source.android.com/devices/camera/external-usb-cameras">https://source.android.com/devices/camera/external-usb-cameras</a><br><code>USB Host</code><br><a href="https://developer.android.com/guide/topics/connectivity/usb/host">https://developer.android.com/guide/topics/connectivity/usb/host</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;如前述文章所述，Google 在 Android P 上提供了对 usb camera 设备的支持，官方叫法是 &lt;code&gt;External USB Cameras&lt;/code&gt; ，提供了完整 HALv3 实现并接入到 &lt;code&gt;CameraProviderManager&lt;/code&gt;；可以让任何三方相机应用轻松调用到外接 USB 摄像头功能，而且使用方法跟内置相机几无差别，都是透过 &lt;code&gt;Android Camera API2&lt;/code&gt; 调用。&lt;/p&gt;
&lt;p&gt;遗憾的是该功能默认关闭，并且 OEM 厂商大概率也会去改 AOSP 代码，比如 multi-caemra，SAT 等功能的实现，有可能会对其造成影响。&lt;/p&gt;
&lt;p&gt;这篇文章详述如何开启 Android 手机上原生支持 USB 外接摄像头这个功能。因为底层走 V4L2 接口，所以支持 UVC 驱动的视频设备都能支持，包括常见的单反，微单，PC 机用的 usb 摄像头，网络摄像头等等，应用非常广泛。&lt;/p&gt;
&lt;p&gt;目前看网络上还没有这方面的相关资料，一些嵌入式设备可能有类似的功能实现 (基于 &lt;code&gt;Linux&lt;/code&gt; 或 &lt;code&gt;Qt&lt;/code&gt;)，基于 android 系统开发的也有可能是直接使用这套方案的。当然也可以实现自己的 HAL 模块并接入 Android Camera HAL 子系统，具体可参考这篇文章介绍 &lt;a href=&quot;/2020/11/18/Android-Camera-HAL-Treble/&quot; title=&quot;Android Camera HAL 新架构&quot;&gt;Android Camera HAL 新架构&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;提示：&lt;br&gt;需要 root 权限的手机，并且可以源码编译&lt;br&gt;如果都没有，退而求其次，备选方案可参考这篇文章 &lt;a href=&quot;/2020/11/02/Android-USB-Camera-Implementations/&quot; title=&quot;Android USB Camera 的实现方案&quot;&gt;Android USB Camera 的实现方案&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
  <entry>
    <title>Android USB Camera 的实现方案</title>
    <link href="https://waterdropw.github.io/2020/11/02/Android-USB-Camera-Implementations/"/>
    <id>https://waterdropw.github.io/2020/11/02/Android-USB-Camera-Implementations/</id>
    <published>2020-11-02T06:36:18.000Z</published>
    <updated>2025-11-20T11:52:36.592Z</updated>
    
    <content type="html"><![CDATA[<p>Android 设备基于 <code>linux kernel</code>, 自带 <code>V4L2</code> 支持，但是 OEM 厂商实现不同，大多默认关闭该功能。所以一般开发者或终端用户想要在 Android 设备上使用 usb camera 不是一件容易的事情。</p><p>这里简单介绍几种针对开发者来说，可选择的实现方案.</p><span id="more"></span><h1 id="基于-libuvc-开发"><a href="#基于-libuvc-开发" class="headerlink" title="基于 libuvc 开发"></a>基于 libuvc 开发</h1><p><a href="https://github.com/libuvc/libuvc">libuvc</a> 是一个跨平台开发库，基于 <code>libusb</code>，功能包括 UVC 设备识别与控制，视频流传输，视频流格式转换等。</p><p>Android 平台上已有一个 Usb Camera 的开源项目，基于 <code>libucv</code> 的Android 应用，<a href="https://github.com/saki4510t/UVCCamera">UVCCamera</a> 无需 <code>root</code> 权限即可预览显示连接到手机的 usb camera 设备。</p><p><code>libuvc</code> 官网介绍：</p><blockquote><p>libuvc is a cross-platform library for USB video devices, built atop libusb. It enables fine-grained control over USB video devices exporting the standard USB Video Class (UVC) interface, enabling developers to write drivers for previously unsupported devices, or just access UVC devices in a generic fashion.</p></blockquote><blockquote><p>libuvc is a library that supports enumeration, control and streaming for USB Video Class (UVC) devices, such as consumer webcams.<br>Features</p></blockquote><ul><li>UVC device discovery and management API</li><li>Video streaming (device to host) with asynchronous&#x2F;callback and synchronous&#x2F;polling modes</li><li>Read&#x2F;write access to standard device settings</li><li>Conversion between various formats: RGB, YUV, JPEG, etc.</li><li>Tested on Mac and Linux, portable to Windows and some BSDs</li></ul><p>代码支持 CMake，android 平台编译：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/libuvc/libuvc</span><br><span class="line"><span class="built_in">cd</span> libuvc</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake \</span><br><span class="line">    -D CMAKE_INSTALL_PREFIX=your_install_path \</span><br><span class="line">    -D CMAKE_TOOLCHAIN_FILE=<span class="variable">$&#123;ANDROID_NDK&#125;</span>/build/cmake/android.toolchain.cmake \</span><br><span class="line">    -D CMAKE_BUILD_TYPE=Debug \</span><br><span class="line">    -D ANDROID_NDK=<span class="variable">$&#123;ANDROID_NDK&#125;</span> \</span><br><span class="line">    -D ANDROID_PLATFORM=android-28 \</span><br><span class="line">    -D ANDROID_STL=c++_static \</span><br><span class="line">    -D ANDROID_PIE=ON \</span><br><span class="line">    ..</span><br><span class="line">cmake --build . --config Debug --target install -- -j6</span><br></pre></td></tr></table></figure><p>UVCCamera</p><blockquote><p>library and sample to access to UVC web camera on non-rooted Android device<br>Copyright (c) 2014-2017 saki <a href="mailto:&#116;&#95;&#x73;&#x61;&#107;&#105;&#x40;&#x73;&#101;&#x72;&#101;&#110;&#101;&#x67;&#x69;&#97;&#110;&#116;&#46;&#99;&#111;&#109;">&#116;&#95;&#x73;&#x61;&#107;&#105;&#x40;&#x73;&#101;&#x72;&#101;&#110;&#101;&#x67;&#x69;&#97;&#110;&#116;&#46;&#99;&#111;&#109;</a></p></blockquote><h1 id="Android-官方推出的-ExternalCamera"><a href="#Android-官方推出的-ExternalCamera" class="headerlink" title="Android 官方推出的 ExternalCamera"></a>Android 官方推出的 ExternalCamera</h1><p>随着 Android P 版本升级，新增了 <code>External USB Cameras</code> 这个功能，默认情况该功能是关闭的，一些 HAL 组件不会编译到 ROM 中，需要打开更新 ROM 才行。另外该功能还依赖于 <code>android.hardware.usb.host</code> 以及 Linux kernel 打开 <code>UVC</code> 驱动支持。</p><p>该实现 HAL 会启动一个 <code>hotplug</code> 线程，监视 <code>/dev/video*</code> 设备节点增删情况，透过 HAL 回调函数通知 <code>CameraProviderManager</code> 更新 camera 设备列表。因为是 Google 原生支持，所以对上层 App Framework 来说，调用方式不需要变，依然调用 <code>Android Camera2 API</code>，只是看到的 cameraId 是类似 <code>/dev/video2</code> 之类的编号（内置相机是0，1，2 … 纯数字编号）</p><p>详细实操过程可以参考这篇文章：</p><a href="/2020/11/12/Android-External-USB-Cameras/" title="Android 外接 USB 摄像头">Android 外接 USB 摄像头</a><h1 id="camera-v4l2-实现"><a href="#camera-v4l2-实现" class="headerlink" title="camera.v4l2 实现"></a>camera.v4l2 实现</h1><p>该库也是基于 <code>V4L2</code> 的 <code>Camera HALv3</code> 实现，原本是 Google 开发出来给树莓派系统使用的。所以从 Android AOSP 代码库里面可以找到这份源代码，但是只有 HAL 实现，没有接入 Android Framework，也就是 cameraserver 是调用不到的。如果有树莓派源代码的话倒是可以参考看看，不过估计也是基于这个初阶版本改过甚至是采用了全新的实现。</p><p>该库在 Android 系统里也是默认关闭的，需要打开才会编到 ROM 里，代码实现上解耦了 camera interface 与 V2L2 wrapper 部分，所以理论上可以把 V4L2 实现替换成其它也是 ok 的。</p><p>详细介绍可以参考这篇文章：</p><a href="/2020/10/25/V4L2-Camera-HALv3/" title="V4L2 Camera HALv3 介绍">V4L2 Camera HALv3 介绍</a><h1 id="usbcamera-HAL"><a href="#usbcamera-HAL" class="headerlink" title="usbcamera HAL"></a>usbcamera HAL</h1><p>Google 早期提供的一个示例代码，是空实现。略过。  </p><p>代码位置：<br><a href="https://android.googlesource.com/platform/hardware/libhardware/+/refs/heads/master/modules/usbcamera/"><code>hardware/libhardware/modules/usbcamera</code></a></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><blockquote><p><code>libuvc</code><br><a href="https://github.com/saki4510t/UVCCamera">https://github.com/saki4510t/UVCCamera</a><br><a href="https://github.com/libuvc/libuvc">https://github.com/libuvc/libuvc</a><br><a href="https://github.com/libusb/libusb">https://github.com/libusb/libusb</a><br><a href="https://ken.tossell.net/libuvc/doc/">https://ken.tossell.net/libuvc/doc/</a><br><a href="https://libusb.info/">https://libusb.info/</a></p></blockquote><blockquote><p><code>external usb camera</code><br><a href="https://source.android.com/devices/camera/external-usb-cameras">https://source.android.com/devices/camera/external-usb-cameras</a><br><a href="https://groups.google.com/g/android-platform/c/Qx1P0I17uzs?pli=1">https://groups.google.com/g/android-platform/c/Qx1P0I17uzs?pli=1</a></p></blockquote><blockquote><p><code>V4L2 Camera Hal</code><br><a href="https://android.googlesource.com/platform/hardware/libhardware/+/master/modules/camera/3_4/README.md">https://android.googlesource.com/platform/hardware/libhardware/+/master/modules/camera/3_4/README.md</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Android 设备基于 &lt;code&gt;linux kernel&lt;/code&gt;, 自带 &lt;code&gt;V4L2&lt;/code&gt; 支持，但是 OEM 厂商实现不同，大多默认关闭该功能。所以一般开发者或终端用户想要在 Android 设备上使用 usb camera 不是一件容易的事情。&lt;/p&gt;
&lt;p&gt;这里简单介绍几种针对开发者来说，可选择的实现方案.&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
  <entry>
    <title>V4L2 Camera HALv3 介绍</title>
    <link href="https://waterdropw.github.io/2020/10/25/V4L2-Camera-HALv3/"/>
    <id>https://waterdropw.github.io/2020/10/25/V4L2-Camera-HALv3/</id>
    <published>2020-10-25T06:13:21.000Z</published>
    <updated>2025-11-20T11:57:13.530Z</updated>
    
    <content type="html"><![CDATA[<p><code>camera.v4l2</code> 实现了 <strong>Camera HALv3</strong> 接口，底层调用了 <code>Video For Linux 2(V4L2)</code>，因此适用范围比较广泛，可以适配兼容 <code>V4L2</code> 接口的所有设备。不过相对于 <code>Android Camera</code> 来说，<code>V4L2</code> 存在一些局限性，内置相机具备的一些功能可能不支持，但对于大多数应用场景来说，是没有问题的。</p><p>这篇文章根据官方介绍，结合实践经验来介绍一下 <code>camera.v4l2</code> 的一些特性。有空再补充一些细节~</p><span id="more"></span><h2 id="当前状态"><a href="#当前状态" class="headerlink" title="当前状态"></a>当前状态</h2><p><code>camera.v4l2</code> 可以自由使用，但是它不是由 <strong>Android Camera team</strong> 官方维护的， 实际上官方维护的是另外一个随着 <strong>Android P</strong> 一起更新发布的实现：<a href="https://source.android.com/devices/camera/external-usb-cameras">External USB Cameras</a></p><p>该 HAL 实现在现有 Android 系统默认是关闭的，不会编译到系统里面。可以按照如下方式打开</p><h2 id="编译方法"><a href="#编译方法" class="headerlink" title="编译方法"></a>编译方法</h2><p>修改 <device>.mk 文件，增加如下配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">USE_CAMERA_V4L2_HAL := true</span><br><span class="line">PRODUCT_PACKAGES += camera.v4l2</span><br><span class="line">PRODUCT_PROPERTY_OVERRIDES += ro.hardware.camera=v4l2</span><br></pre></td></tr></table></figure><p>第一行会打开编译选项，默认关闭，防止一些设备不支持出现问题。第二行告诉编译系统将库打包到 <code>system image</code> 里面；最后一行告诉硬件设备管理器加载 <code>V4L2 HAL</code> 替换掉默认的 <code>Camera HAL</code>.</p><h2 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h2><ul><li>camera 必须支持 <code>BGR32</code>, <code>YUV420</code> 和 <code>JPEG</code> 格式</li><li>设备上的 <strong>gralloc</strong> 和其它 <strong>graphics module</strong> 必须使用 <code>HAL_PIXEL_FORMAT_RGBA_8888</code> 作为 <code>HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED</code></li></ul><h2 id="HAL-代码解析"><a href="#HAL-代码解析" class="headerlink" title="HAL 代码解析"></a>HAL 代码解析</h2><p><strong>V4L2 Camera HAL</strong> 包含 3 个部分：HALv3 Camera 实现， V4L2 wrapper，以及 Metadata</p><p>同时，你应该要了解一下 <strong>Android Framework</strong> 是如何与 <strong>HAL</strong> 打交道的，可以参考 <a href="/2020/10/23/Android-Camera-HAL-Intro/" title="Android Camera HAL 介绍">Android Camera HAL 介绍</a></p><h3 id="Camera-amp-HAL-接口"><a href="#Camera-amp-HAL-接口" class="headerlink" title="Camera &amp; HAL 接口"></a>Camera &amp; HAL 接口</h3><p>接口实现主要是这两个类：<code>Camera</code>, <code>V4L2CameraHal</code></p><p><code>V4L2CameraHAL</code> 主要负责相机系统初始化，创建时，会搜索 <code>dev/video*</code> 设备节点，并查询是否满足 <code>V4L2_CAP_VIDEO_CAPTURE</code> 然后创建对应的 <code>V4L2Camera</code> 对象，并且对 Framework 可见。后续流程调用会被 dispatch 到特定的设备节点。</p><p><code>Camera</code> 类实现了 camera 设备的通用操作，打开&#x2F;关闭设备、configuring streams、preparing and tradking requests 等等。具体的拍照、设置流程则是由其子类 <code>V4L2Camera</code> 实现。</p><p><code>Camera</code> 类在调用具体流程的时候，会应用上 <code>V4L2Camera</code> 初始化之后的 <code>Metadata</code> 属性，比如 <strong>in-flight</strong> request per stream 数量的限制。换句话说，<code>Camera</code> 类实现具体的 HAL 调用流程，与而具体的设备无关，而 <code>V4L2Camera</code> 负责设备相关的属性设置、功能实现（透过 <code>V4L2Wrapper</code> 类）。所以理论上，可以把 V4L2 实现换成其它某种设备实现，只要传递正确的 metadata 信息，<code>Camera</code> 类依然会按照预期的工作。</p><h3 id="V4L2-具体实现"><a href="#V4L2-具体实现" class="headerlink" title="V4L2 具体实现"></a>V4L2 具体实现</h3><p><code>V4L2Camera</code> 实现所有拍照功能。它包含一些方法用来获取或设置参数，但它的核心能力主要是在 <code>request queue</code> 上。 <code>Camera</code> 提交 <code>CaptureRequest</code> 到 <code>request queue</code> 排队，<code>V4L2Camera</code> 异步地从队列里取出来执行，处理过程主要分三个阶段：</p><ul><li>接收 request 请求：收到 request 并放入等待队列。</li><li>enqueue：读取 request 配置并应用到 v4l2 设备，执行拍照，并传递 buffer 给 v4l2 驱动。</li><li>dequeue：从驱动获取到处理完成的 frame，buffer 内容 copy 到 request output 并传递给 <code>Camera</code> 做后续处理（验证结果，填入 <code>CaptureResult</code> 并返回给 Framework）</li></ul><p>这项工作的大部分是 <code>V4L2Wrapper</code> 类完成的，它基于 HAL 的功能需求，包装了 v4l2 ioctls, 提供简单的输入输出调用功能。自动填入 ioctls 需要的常量参数，抽取 HAL 所需信息，同时把相关功能暴露给 Metadata 系统，获取、设置 meta 控制参数。</p><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p><code>Metadata</code> 子系统主要目的是简化 (system&#x2F;media&#x2F;camera&#x2F;docs&#x2F;docs.html) 的相关操作。顶层是 <code>Metadata</code> 和 <code>PartialMetadataInterface</code> 类，<code>Metadata</code> 类提供高层次功能，包括初始化 <code>static metadata</code>，验证，获取、设定相关配置参数等等，它把这些需求下发给对应的 <code>PartialMetadataInterfaces</code> 模块，各个子模块负责处理自己相关的 metadata 和任务。</p><p>已经实现了几个具体类负责这项功能，主要有 3 类：</p><ul><li>Properties：静态属性, static metadata 等</li><li>Controls：动态属性，或者标示允许值的静态属性</li><li>States：动态的只读的属性</li></ul><p>针对不同的功能需求和不同的 <code>metadata tags</code>, 还有一些更具体的接口和子类型来区分处理。</p><h4 id="Metadata-Factory"><a href="#Metadata-Factory" class="headerlink" title="Metadata Factory"></a>Metadata Factory</h4><p>为了满足 HAL 规范的要求, V4L2 Camera HAL 使用一个 metadata factory 工厂方法，初始化 100+ metadata 参数，大多数参数都是固定值，只有少部分对应到 v4l2 驱动相关的参数。</p><p>这套 HAL 实现最初是为了提供给 <strong>Raspberry Pi</strong> camera module v2.1 使用的，所以大多固定默认值的设置主要是适配它的相机模组。</p><h2 id="V4L2-不足之处"><a href="#V4L2-不足之处" class="headerlink" title="V4L2 不足之处"></a>V4L2 不足之处</h2><ul><li>不支持多个 <code>stream</code>，如果 <strong>preview</strong> 与 <strong>capture</strong> 格式不一样，必须重新配置 <code>stream</code>; 因此不支持 <strong>Android Camera (v1) API</strong>，只能使用 <strong>Camera2 API</strong></li><li>有些 metadata 信息无法从 V4L2 获取到，比如一些物理属性</li><li>Android 系统实现要求 HAL 必须支持 YUV420， JPEG 以及 Graphics 子系统定义的（implementation defined），但实际上只有少数 camera 完整支持这几种格式（比如树莓派相机），因此 HAL 内部实现了格式转换以扩展其适用范围。</li><li>V4L2 并不能确保参数设置立即生效，所以也没有办法确认当前帧给定的设置是否已生效。因此 <code>CaptureRequest</code> 和 <code>CaptureResult</code> 所带的参数有可能生效，有可能没有。在使用到这些参数的时候，需要注意，它不一定是准确的。</li><li>另外，V4L2 的很多功能，并没有包含在 HAL 实现里面(比如与camera功能无关的),所以功能上讲, HAL 只是完整 V4L2 的一个子集。</li></ul><h2 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h2><ul><li>该库未实现的功能包括：high speed capture, flash torch mode, hotplugging&#x2F;unplugging</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;camera.v4l2&lt;/code&gt; 实现了 &lt;strong&gt;Camera HALv3&lt;/strong&gt; 接口，底层调用了 &lt;code&gt;Video For Linux 2(V4L2)&lt;/code&gt;，因此适用范围比较广泛，可以适配兼容 &lt;code&gt;V4L2&lt;/code&gt; 接口的所有设备。不过相对于 &lt;code&gt;Android Camera&lt;/code&gt; 来说，&lt;code&gt;V4L2&lt;/code&gt; 存在一些局限性，内置相机具备的一些功能可能不支持，但对于大多数应用场景来说，是没有问题的。&lt;/p&gt;
&lt;p&gt;这篇文章根据官方介绍，结合实践经验来介绍一下 &lt;code&gt;camera.v4l2&lt;/code&gt; 的一些特性。有空再补充一些细节~&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
  <entry>
    <title>Android Camera HAL 介绍</title>
    <link href="https://waterdropw.github.io/2020/10/23/Android-Camera-HAL-Intro/"/>
    <id>https://waterdropw.github.io/2020/10/23/Android-Camera-HAL-Intro/</id>
    <published>2020-10-23T02:48:12.000Z</published>
    <updated>2025-11-20T11:52:00.518Z</updated>
    
    <content type="html"><![CDATA[<p>Android Camera HAL 作为 Framework 层 Camera2 API 接口与底层硬件实现的桥梁，起着承上启下的作用。另外从 <code>Android 8.0</code> 开始使用了新的 <code>Treble</code> 架构（HAL 接口与实现代码在 <code>hardware/interfaces/camera/</code>），舍弃了原本旧的架构实现（Legacy HAL: <code>hardware/libhardware/modules/camera/</code>）。</p><p>Legacy HAL 当前还保留的内容：</p><ul><li><code>hardware/libhardware/include/hardware/camera*.h</code>, Camera Hal 接口定义，持续更新</li><li><code>hardware/libhardware/modules/camera/3_0/</code>, <code>camera.default</code> Legacy 默认实现</li><li><code>hardware/libhardware/modules/camera/3_4/</code>, <code>camera.v4l2</code> 非官方实现（树莓派）0</li></ul><p>截止目前最新版本是 HALv3，高端机型基本上都支持。Camera HAL 属于相对比较复杂的一个硬件模块，随着硬件模组的发展，HAL 接口也在不断变化 v1, v2 对应 <code>android.hardware.Camera</code> API, 已经不再被支持。</p><p>熟悉了 <a href="/2020/10/22/Android-HAL-Intro/" title="Android HAL 介绍">Android HAL 介绍</a> ，再来看 Camera HAL 会更容易理解。</p><span id="more"></span><h1 id="Treble-架构下的-Camera-HAL"><a href="#Treble-架构下的-Camera-HAL" class="headerlink" title="Treble 架构下的 Camera HAL"></a>Treble 架构下的 Camera HAL</h1><img src="/images/camera/ape_fwk_camera2.jpg" class="" title="100% 100% Camera HAL 新架构"><p>看图说话，简单总结一下：</p><ol><li>Camera 子系统可以分成三层来看，从上到下分别是 <code>App/Framework</code>，<code>CameraService</code>，<code>HAL Impl</code></li><li><code>App/Framework</code> vs <code>CameraService</code> 之间，通过 <code>AIDL</code> binder 通信</li><li><code>CameraService</code> vs <code>Camera HAL</code> 之间，通过 <code>HIDL</code> binder 通信</li></ol><p>Treble 架构下，为了满足更多的 IPC binder 调用，提供了 3 个 binder 设备：</p><ul><li><code>/dev/binder</code>, 最早出现的 binder 设备，BnXXX， BpXXX 的 Service&#x2F;Client 实现基础，<code>Android 8.0</code> 之后保留给 <code>Android Framework</code> 专用，vendor 实现无法访问。</li><li><code>/dev/vndbinder</code>, 大部分硬件 HAL 设备使用该节点与上层通信，比如 camera，bluetooth，nfc，sensors</li><li><code>/dev/hwbinder</code>, HIDL 实现的进程间通信都可以用</li></ul><p>内容比较多，单独更新一篇文章来讲：<a href="/2020/11/18/Android-Camera-HAL-Treble/" title="Android Camera HAL 新架构">Android Camera HAL 新架构</a></p><h1 id="Legacy-Camera-HAL"><a href="#Legacy-Camera-HAL" class="headerlink" title="Legacy Camera HAL"></a>Legacy Camera HAL</h1><h2 id="HAL-接口介绍"><a href="#HAL-接口介绍" class="headerlink" title="HAL 接口介绍"></a>HAL 接口介绍</h2><p>模块名称定义如下，加载模块时根据模块名称搜索对应的动态库 <code>camera.variant.so</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_HARDWARE_MODULE_ID <span class="string">&quot;camera&quot;</span></span></span><br></pre></td></tr></table></figure><blockquote><p>模块接口，camera 通用方法，全局信息的查询。调用时要注意有些方法是无效的，调用前一定要做判空处理，兼容性查询 API 说明。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; libhardware/include/hardware/camera_common.h</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">camera_module</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Common methods of the camera module.  This *must* be the first member of</span></span><br><span class="line"><span class="comment">     * camera_module as users of this structure will cast a hw_module_t to</span></span><br><span class="line"><span class="comment">     * camera_module pointer in contexts where it&#x27;s known the hw_module_t</span></span><br><span class="line"><span class="comment">     * references a camera_module.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">hw_module_t</span> common;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">int</span> (*get_number_of_cameras)(<span class="type">void</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">int</span> (*get_camera_info)(<span class="type">int</span> camera_id, <span class="keyword">struct</span> camera_info *info);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_1_0, CAMERA_MODULE_API_VERSION_2_0:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *    Not provided by HAL module. Framework may not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_2_1:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *    Valid to be called by the framework.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*set_callbacks)(<span class="type">const</span> <span class="type">camera_module_callbacks_t</span> *callbacks);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_1_x/2_0/2_1:</span></span><br><span class="line"><span class="comment">     *    Not provided by HAL module. Framework may not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_2_2:</span></span><br><span class="line"><span class="comment">     *    Valid to be called by the framework.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">void</span> (*get_vendor_tag_ops)(<span class="type">vendor_tag_ops_t</span>* ops);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_1_x/2_0/2_1/2_2:</span></span><br><span class="line"><span class="comment">     *    Not provided by HAL module. Framework will not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  CAMERA_MODULE_API_VERSION_2_3:</span></span><br><span class="line"><span class="comment">     *    Valid to be called by the framework.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*open_legacy)(<span class="type">const</span> <span class="keyword">struct</span> <span class="type">hw_module_t</span>* <span class="keyword">module</span>, <span class="type">const</span> <span class="type">char</span>* id,</span><br><span class="line">            <span class="type">uint32_t</span> halVersion, <span class="keyword">struct</span> <span class="type">hw_device_t</span>** device);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_1_x/2_0/2_1/2_2/2_3:</span></span><br><span class="line"><span class="comment">     *   Not provided by HAL module. Framework will not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_2_4:</span></span><br><span class="line"><span class="comment">     *   Valid to be called by the framework.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*set_torch_mode)(<span class="type">const</span> <span class="type">char</span>* camera_id, <span class="type">bool</span> enabled);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_1_x/2_0/2_1/2_2/2_3:</span></span><br><span class="line"><span class="comment">     *   Not provided by HAL module. Framework will not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_2_4:</span></span><br><span class="line"><span class="comment">     *   If not NULL, will always be called by the framework once after the HAL</span></span><br><span class="line"><span class="comment">     *   module is loaded, before any other HAL module method is called.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*init)();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_1_x/2_0/2_1/2_2/2_3/2_4:</span></span><br><span class="line"><span class="comment">     *   Not provided by HAL module. Framework will not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_2_5 or higher:</span></span><br><span class="line"><span class="comment">     *   If any of the camera devices accessible through this camera module is</span></span><br><span class="line"><span class="comment">     *   a logical multi-camera, and at least one of the physical cameras isn&#x27;t</span></span><br><span class="line"><span class="comment">     *   a stand-alone camera device, this function will be called by the camera</span></span><br><span class="line"><span class="comment">     *   framework. Calling this function with invalid physical_camera_id will</span></span><br><span class="line"><span class="comment">     *   get -EINVAL, and NULL static_metadata.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*get_physical_camera_info)(<span class="type">int</span> physical_camera_id,</span><br><span class="line">            <span class="type">camera_metadata_t</span> **static_metadata);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Version information (based on camera_module_t.common.module_api_version):</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_1_x/2_0/2_1/2_2/2_3/2_4:</span></span><br><span class="line"><span class="comment">     *   Not provided by HAL module. Framework will not call this function.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * CAMERA_MODULE_API_VERSION_2_5 or higher:</span></span><br><span class="line"><span class="comment">     *   Valid to be called by the framework.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*is_stream_combination_supported)(<span class="type">int</span> camera_id,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera_stream_combination_t</span> *streams);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * notify_device_state_change:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Notify the camera module that the state of the overall device has</span></span><br><span class="line"><span class="comment">     * changed in some way that the HAL may want to know about.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">void</span> (*notify_device_state_change)(<span class="type">uint64_t</span> deviceState);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * get_camera_device_version:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Return the device version for a given camera device. This value may not change for a camera</span></span><br><span class="line"><span class="comment">     * device. The version returned here must be the same as the one from get_camera_info.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*get_camera_device_version)(<span class="type">int</span> camera_id, <span class="type">uint32_t</span> *version);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* reserved for future use */</span></span><br><span class="line">    <span class="type">void</span>* reserved[<span class="number">1</span>];</span><br><span class="line">&#125; <span class="type">camera_module_t</span>;</span><br></pre></td></tr></table></figure><p>Camera HALv1, v2, v3，<code>camera3_device</code> 的定义，注意 <code>device_ops_t</code> 支持的接口不一致。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; libhardware/include/hardware/camera3.h</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">camera3_device</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * common.version must equal CAMERA_DEVICE_API_VERSION_3_0 to identify this</span></span><br><span class="line"><span class="comment">     * device as implementing version 3.0 of the camera device HAL.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Camera open (common.module-&gt;common.methods-&gt;open) should return in 200ms, and must return</span></span><br><span class="line"><span class="comment">     * in 500ms.</span></span><br><span class="line"><span class="comment">     * Camera close (common.close) should return in 200ms, and must return in 500ms.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">hw_device_t</span> common;</span><br><span class="line">    <span class="type">camera3_device_ops_t</span> *ops;</span><br><span class="line">    <span class="type">void</span> *priv;</span><br><span class="line">&#125; <span class="type">camera3_device_t</span>;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; libhardware/include/hardware/camera2.h</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">camera2_device</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * common.version must equal CAMERA_DEVICE_API_VERSION_2_0 to identify</span></span><br><span class="line"><span class="comment">     * this device as implementing version 2.0 of the camera device HAL.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">hw_device_t</span> common;</span><br><span class="line">    <span class="type">camera2_device_ops_t</span> *ops;</span><br><span class="line">    <span class="type">void</span> *priv;</span><br><span class="line">&#125; <span class="type">camera2_device_t</span>;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; libhardware/include/hardware/camera.h</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">camera_device</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * camera_device.common.version must be in the range</span></span><br><span class="line"><span class="comment">     * HARDWARE_DEVICE_API_VERSION(0,0)-(1,FF). CAMERA_DEVICE_API_VERSION_1_0 is</span></span><br><span class="line"><span class="comment">     * recommended.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">hw_device_t</span> common;</span><br><span class="line">    <span class="type">camera_device_ops_t</span> *ops;</span><br><span class="line">    <span class="type">void</span> *priv;</span><br><span class="line">&#125; <span class="type">camera_device_t</span>;</span><br></pre></td></tr></table></figure><p>HALv3 设备功能接口，注意不同子版本对 API 的支持情况不同。因为涉及到底层硬件操作，每个调用有性能要求，同步调用不能超时。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; libhardware/include/hardware/camera3.h</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">camera3_device_ops</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * initialize:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * One-time initialization to pass framework callback function pointers to</span></span><br><span class="line"><span class="comment">     * the HAL. Will be called once after a successful open() call, before any</span></span><br><span class="line"><span class="comment">     * other functions are called on the camera3_device_ops structure.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * This should be a non-blocking call. The HAL should return from this call</span></span><br><span class="line"><span class="comment">     * in 5ms, and must return from this call in 10ms.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*initialize)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera3_callback_ops_t</span> *callback_ops);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * The HAL should return from this call in 500ms, and must return from this</span></span><br><span class="line"><span class="comment">     * call in 1000ms.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*configure_streams)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *,</span><br><span class="line">            <span class="type">camera3_stream_configuration_t</span> *stream_list);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * This should be a non-blocking call. The HAL should return from this call</span></span><br><span class="line"><span class="comment">     * in 1ms, and must return from this call in 5ms.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*register_stream_buffers)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera3_stream_buffer_set_t</span> *buffer_set);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * This should be a non-blocking call. The HAL should return from this call</span></span><br><span class="line"><span class="comment">     * in 1ms, and must return from this call in 5ms.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">const</span> <span class="type">camera_metadata_t</span>* (*construct_default_request_settings)(</span><br><span class="line">            <span class="type">const</span> <span class="keyword">struct</span> camera3_device *,</span><br><span class="line">            <span class="type">int</span> type);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performance considerations:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Handling a new buffer should be extremely lightweight and there should be</span></span><br><span class="line"><span class="comment">     * no frame rate degradation or frame jitter introduced.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * This call must return fast enough to ensure that the requested frame</span></span><br><span class="line"><span class="comment">     * rate can be sustained, especially for streaming cases (post-processing</span></span><br><span class="line"><span class="comment">     * quality settings set to FAST). The HAL should return this call in 1</span></span><br><span class="line"><span class="comment">     * frame interval, and must return from this call in 4 frame intervals.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*process_capture_request)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *,</span><br><span class="line">            <span class="type">camera3_capture_request_t</span> *request);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * &gt;= CAMERA_DEVICE_API_VERSION_3_2:</span></span><br><span class="line"><span class="comment">     *    DEPRECATED. This function has been deprecated and should be set to</span></span><br><span class="line"><span class="comment">     *    NULL by the HAL.  Please implement get_vendor_tag_ops in camera_common.h</span></span><br><span class="line"><span class="comment">     *    instead.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">void</span> (*get_metadata_vendor_tag_ops)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device*,</span><br><span class="line">            <span class="type">vendor_tag_query_ops_t</span>* ops);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * dump:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Print out debugging state for the camera device. This will be called by</span></span><br><span class="line"><span class="comment">     * the framework when the camera service is asked for a debug dump, which</span></span><br><span class="line"><span class="comment">     * happens when using the dumpsys tool, or when capturing a bugreport.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * The passed-in file descriptor can be used to write debugging text using</span></span><br><span class="line"><span class="comment">     * dprintf() or write(). The text should be in ASCII encoding only.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * This must be a non-blocking call. The HAL should return from this call</span></span><br><span class="line"><span class="comment">     * in 1ms, must return from this call in 10ms. This call must avoid</span></span><br><span class="line"><span class="comment">     * deadlocks, as it may be called at any point during camera operation.</span></span><br><span class="line"><span class="comment">     * Any synchronization primitives used (such as mutex locks or semaphores)</span></span><br><span class="line"><span class="comment">     * should be acquired with a timeout.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">void</span> (*dump)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *, <span class="type">int</span> fd);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performance requirements:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * The HAL should return from this call in 100ms, and must return from this</span></span><br><span class="line"><span class="comment">     * call in 1000ms. And this call must not be blocked longer than pipeline</span></span><br><span class="line"><span class="comment">     * latency (see S7 for definition).</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Version information:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *   only available if device version &gt;= CAMERA_DEVICE_API_VERSION_3_1.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*flush)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device *);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * signal_stream_flush:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;= CAMERA_DEVICE_API_VERISON_3_5:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *    Not defined and must be NULL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &gt;= CAMERA_DEVICE_API_VERISON_3_6:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">void</span> (*signal_stream_flush)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device*,</span><br><span class="line">            <span class="type">uint32_t</span> num_streams,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera3_stream_t</span>* <span class="type">const</span>* streams);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * is_reconfiguration_required:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;= CAMERA_DEVICE_API_VERISON_3_5:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *    Not defined and must be NULL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &gt;= CAMERA_DEVICE_API_VERISON_3_6:</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">int</span> (*is_reconfiguration_required)(<span class="type">const</span> <span class="keyword">struct</span> camera3_device*,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera_metadata_t</span>* old_session_params,</span><br><span class="line">            <span class="type">const</span> <span class="type">camera_metadata_t</span>* new_session_params);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* reserved for future use */</span></span><br><span class="line">    <span class="type">void</span> *reserved[<span class="number">6</span>];</span><br><span class="line">&#125; <span class="type">camera3_device_ops_t</span>;</span><br></pre></td></tr></table></figure><h2 id="module-API-version"><a href="#module-API-version" class="headerlink" title="module API version"></a>module API version</h2><blockquote><p>当前推荐版本是 <code>CAMERA_MODULE_API_VERSION_2_5</code></p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; include/hardware/camera_common.h</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * All module versions &lt;= HARDWARE_MODULE_API_VERSION(1, 0xFF) must be treated</span></span><br><span class="line"><span class="comment"> * as CAMERA_MODULE_API_VERSION_1_0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_1_0 HARDWARE_MODULE_API_VERSION(1, 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_0 HARDWARE_MODULE_API_VERSION(2, 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_1 HARDWARE_MODULE_API_VERSION(2, 1)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_2 HARDWARE_MODULE_API_VERSION(2, 2)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_3 HARDWARE_MODULE_API_VERSION(2, 3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_4 HARDWARE_MODULE_API_VERSION(2, 4)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_2_5 HARDWARE_MODULE_API_VERSION(2, 5)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_MODULE_API_VERSION_CURRENT CAMERA_MODULE_API_VERSION_2_5</span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">camera_module_t</span>.common.module_api_version</span><br></pre></td></tr></table></figure><ul><li>major: MSB 16bit</li><li>minor: LSB 16bit</li></ul><h3 id="Versions-0-X-1-X-CAMERA-MODULE-API-VERSION-1-0"><a href="#Versions-0-X-1-X-CAMERA-MODULE-API-VERSION-1-0" class="headerlink" title="Versions: 0.X - 1.X [CAMERA_MODULE_API_VERSION_1_0]"></a>Versions: 0.X - 1.X [CAMERA_MODULE_API_VERSION_1_0]</h3><ul><li>HAL interface 的初版 module 实现</li><li>透过该版本 module 可打开的 camera 设备，仅仅支持 android.hardware.Camera API </li><li><code>camera_info.device_version</code> 无效</li><li><code>camera_info.static_camera_characteristics</code> 无效</li></ul><h3 id="Version-2-0-CAMERA-MODULE-API-VERSION-2-0"><a href="#Version-2-0-CAMERA-MODULE-API-VERSION-2-0" class="headerlink" title="Version: 2.0 [CAMERA_MODULE_API_VERSION_2_0]"></a>Version: 2.0 [CAMERA_MODULE_API_VERSION_2_0]</h3><ul><li>支持 1.0， 2.0 HAL 接口</li><li><code>camera_info.device_version</code> 有效</li><li><code>camera_info.static_camera_characteristics</code> 在 device_version &gt;&#x3D; 2.0 时有效</li></ul><h3 id="Version-2-1-CAMERA-MODULE-API-VERSION-2-1"><a href="#Version-2-1-CAMERA-MODULE-API-VERSION-2-1" class="headerlink" title="Version: 2.1 [CAMERA_MODULE_API_VERSION_2_1]"></a>Version: 2.1 [CAMERA_MODULE_API_VERSION_2_1]</h3><ul><li>增加异步回调支持，用来通知 framework 底层状态的变化</li><li><code>set_callbacks</code> 必须是该版本及其以上才支持</li></ul><h3 id="Version-2-2-CAMERA-MODULE-API-VERSION-2-2"><a href="#Version-2-2-CAMERA-MODULE-API-VERSION-2-2" class="headerlink" title="Version: 2.2 [CAMERA_MODULE_API_VERSION_2_2]"></a>Version: 2.2 [CAMERA_MODULE_API_VERSION_2_2]</h3><ul><li>module 层面增加 vendor tag 支持</li><li><code>vendor_tag_query_ops</code> 透过打开的 device 才能调用，不再推荐使用</li></ul><h3 id="Version-2-3-CAMERA-MODULE-API-VERSION-2-3"><a href="#Version-2-3-CAMERA-MODULE-API-VERSION-2-3" class="headerlink" title="Version: 2.3 [CAMERA_MODULE_API_VERSION_2_3]"></a>Version: 2.3 [CAMERA_MODULE_API_VERSION_2_3]</h3><ul><li>支持打开 legacy device</li><li>前提是 device 具备多个 device API 实现</li><li><code>common.methods-&gt;open</code> 默认打开的还是最新版本的 device</li></ul><h3 id="Version-2-4-CAMERA-MODULE-API-VERSION-2-4"><a href="#Version-2-4-CAMERA-MODULE-API-VERSION-2-4" class="headerlink" title="Version: 2.4 [CAMERA_MODULE_API_VERSION_2_4]"></a>Version: 2.4 [CAMERA_MODULE_API_VERSION_2_4]</h3><ul><li>Torch mode 支持，framework 可以在不打开 device 情况下使用 torch mode；当然 camera device 具有最高优先级使用 flash；当打开相机设备时，HAL 透过 callback 通知 framework torch mode 已关闭</li><li>external camera （例如 USB camera）支持. <code>CAMERA_DEVICE_STATUS_PRESENT</code> 才可获取设备状态，否则无效。framework 注册 callback 接收hot-plug camera 状态，并更新可用的设备列表</li><li>Camera arbitration hints， 增加提示信息：同时打开使用的相机个数， <code>get_camera_info</code> 调用返回后，<code>camera_info.resource_cost</code>, <code>camera_info.conflicting_devices</code>必须被设置</li><li>module 初始化支持，在模块被加载后，其它方法被调用之前，初始化被调用，做一次性的初始化工作</li></ul><h3 id="Version-2-5-CAMERA-MODULE-API-VERSION-2-5"><a href="#Version-2-5-CAMERA-MODULE-API-VERSION-2-5" class="headerlink" title="Version: 2.5 [CAMERA_MODULE_API_VERSION_2_5]"></a>Version: 2.5 [CAMERA_MODULE_API_VERSION_2_5]</h3><ul><li>可查询对象可以是逻辑相机，而不仅仅是物理相机设备</li><li>增加 stream combination 能力查询</li><li>完整的设备状态通知，比如 shutter 的 folding&#x2F;unfolding, covering&#x2F;uncovering</li></ul><h2 id="device-API-version"><a href="#device-API-version" class="headerlink" title="device API version"></a>device API version</h2><blockquote><p>当前推荐使用的版本是 <code>CAMERA_DEVICE_API_VERSION_3_5</code></p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * All device versions &lt;= HARDWARE_DEVICE_API_VERSION(1, 0xFF) must be treated</span></span><br><span class="line"><span class="comment"> * as CAMERA_DEVICE_API_VERSION_1_0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_1_0 HARDWARE_DEVICE_API_VERSION(1, 0) <span class="comment">// DEPRECATED</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_2_0 HARDWARE_DEVICE_API_VERSION(2, 0) <span class="comment">// NO LONGER SUPPORTED</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_2_1 HARDWARE_DEVICE_API_VERSION(2, 1) <span class="comment">// NO LONGER SUPPORTED</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_0 HARDWARE_DEVICE_API_VERSION(3, 0) <span class="comment">// NO LONGER SUPPORTED</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_1 HARDWARE_DEVICE_API_VERSION(3, 1) <span class="comment">// NO LONGER SUPPORTED</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_2 HARDWARE_DEVICE_API_VERSION(3, 2)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_3 HARDWARE_DEVICE_API_VERSION(3, 3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_4 HARDWARE_DEVICE_API_VERSION(3, 4)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_5 HARDWARE_DEVICE_API_VERSION(3, 5)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_3_6 HARDWARE_DEVICE_API_VERSION(3, 6)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Device version 3.5 is current, older HAL camera device versions are not</span></span><br><span class="line"><span class="comment">// recommended for new devices.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAMERA_DEVICE_API_VERSION_CURRENT CAMERA_DEVICE_API_VERSION_3_5</span></span><br></pre></td></tr></table></figure><p>Camera device HAL 3.6[ CAMERA_DEVICE_API_VERSION_3_6 ], 是当前推荐支持的版本</p><ul><li>支持 <code>android.hardware.Camera</code> API</li><li>有限的 <code>android.hardware.Camera2</code> API</li></ul><p><code>CAMERA_DEVICE_API_VERSION_3_2</code> 及以上</p><ul><li><code>camera_module_t.common.module_api_version</code> 最低要求 <code>2.2</code></li></ul><p><code>CAMERA_DEVICE_API_VERSION_3_1</code> 及以下</p><ul><li><code>camera_module_t.common.module_api_version</code> 最低要求 <code>2.0</code></li></ul><p><code>CAMERA_DEVICE_API_VERSION_2_0</code> 及以下</p><ul><li><code>camera_module_t.common.module_api_version</code> 要求<code>1.0</code></li></ul><h3 id="1-0-初版-Android-camera-HAL-Android-4-0-camera-h"><a href="#1-0-初版-Android-camera-HAL-Android-4-0-camera-h" class="headerlink" title="1.0: 初版 Android camera HAL (Android 4.0) [camera.h]"></a>1.0: 初版 Android camera HAL (Android 4.0) [camera.h]</h3><ul><li>由 C++ <code>CameraHardwareInterface</code> 抽象接口转换而来</li><li>支持 <code>android.hardware.Camera</code> API</li></ul><h3 id="2-0-Initial-release-of-expanded-capability-HAL-Android-4-2-camera2-h"><a href="#2-0-Initial-release-of-expanded-capability-HAL-Android-4-2-camera2-h" class="headerlink" title="2.0: Initial release of expanded-capability HAL (Android 4.2) [camera2.h]"></a>2.0: Initial release of expanded-capability HAL (Android 4.2) [camera2.h]</h3><ul><li>完整实现 <code>android.hardware.Camera</code> API</li><li>允许 camera service 持有 ZSL queue</li><li>新增功能尚未做完整测试：manual capture control, Bayer RAW capture, reprocessing of RAW data</li></ul><h3 id="3-0-First-revision-of-expanded-capability-HAL"><a href="#3-0-First-revision-of-expanded-capability-HAL" class="headerlink" title="3.0: First revision of expanded-capability HAL"></a>3.0: First revision of expanded-capability HAL</h3><ul><li>最低要求 module 版本 <code>2.0</code> 及以上</li><li>重写了 input request 和 stream queue 接口</li><li>合并 <code>trigger</code> 到 <code>request</code> 里面；合并<code>notification</code>到<code>results</code></li><li>合并所有<code>callback</code>到一个结构体里面；合并初始化设置到一个初始化函数调用里</li><li>合并<code>stream</code>配置到一个调用里；双向流替换<code>STREAM_FROM_STREAM</code>结构</li><li>旧版本的有限支持</li></ul><h3 id="3-1-Minor-revision-of-expanded-capability-HAL"><a href="#3-1-Minor-revision-of-expanded-capability-HAL" class="headerlink" title="3.1: Minor revision of expanded-capability HAL"></a>3.1: Minor revision of expanded-capability HAL</h3><ul><li><code>configure_streams</code>传递<code>consumer usage flags</code>到 HAL </li><li><code>flush</code>调用将丢弃所有未处理完的 <code>requests/buffers</code></li></ul><h3 id="3-2-Minor-revision-of-expanded-capability-HAL"><a href="#3-2-Minor-revision-of-expanded-capability-HAL" class="headerlink" title="3.2: Minor revision of expanded-capability HAL"></a>3.2: Minor revision of expanded-capability HAL</h3><ul><li>废弃<code>get_metadata_vendor_tag_ops</code>，使用<code>get_vendor_tag_ops</code>代替</li><li>废弃<code>register_stream_buffers</code>，<code>process_capture_request</code>传递给 HAL 的 gralloc buffer 是由 framework 新分配的</li><li>新增<code>partial result</code>支持，可以多次调用<code>process_capture_result</code>，获取到的是调用时刻 ready 的结果，是最终结果的子集</li><li>新增<code>manual templete</code> 到 <code>camera3_request_template</code>，应用可直接用来控制拍照设置</li><li>重写双向流、输入流的定义 spec</li><li>改变返回结果的路径，由<code>process_capture_result</code>返回，不再是<code>process_capture_request</code></li></ul><h3 id="3-3-Minor-revision-of-expanded-capability-HAL"><a href="#3-3-Minor-revision-of-expanded-capability-HAL" class="headerlink" title="3.3: Minor revision of expanded-capability HAL"></a>3.3: Minor revision of expanded-capability HAL</h3><ul><li>API 更新：OPAQUE, YUV reprocessing</li><li>增加深度图输出支持</li><li><code>camera3_stream_t</code>增加<code>data_space</code>, <code>rotation</code></li><li><code>camera3_stream_configuration_t</code>增加 camera3 流配置模式</li></ul><h3 id="3-4-Minor-additions-to-supported-metadata-and-changes-to-data-space-support"><a href="#3-4-Minor-additions-to-supported-metadata-and-changes-to-data-space-support" class="headerlink" title="3.4: Minor additions to supported metadata and changes to data_space support"></a>3.4: Minor additions to supported metadata and changes to data_space support</h3><ul><li><code>RAW_OPAQUE</code>格式增加 <code>ANDROID_SENSOR_OPAQUE_RAW_SIZE</code>参数</li><li>Raw 格式增加 <code>ANDROID_CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE</code> 参数</li><li>重定义<code>camera3_stream_t.data_space</code>，用法更灵活</li><li>HALv3.2 以上增加如下几个通用 metadata<ul><li>ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL_3</li><li>ANDROID_CONTROL_POST_RAW_SENSITIVITY_BOOST</li><li>ANDROID_CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE</li><li>ANDROID_SENSOR_DYNAMIC_BLACK_LEVEL</li><li>ANDROID_SENSOR_DYNAMIC_WHITE_LEVEL</li><li>ANDROID_SENSOR_OPAQUE_RAW_SIZE</li><li>ANDROID_SENSOR_OPTICAL_BLACK_REGIONS</li></ul></li></ul><h3 id="3-5-Minor-revisions-to-support-session-parameters-and-logical-multi-camera"><a href="#3-5-Minor-revisions-to-support-session-parameters-and-logical-multi-camera" class="headerlink" title="3.5: Minor revisions to support session parameters and logical multi camera:"></a>3.5: Minor revisions to support session parameters and logical multi camera:</h3><ul><li>增加<code>ANDROID_REQUEST_AVAILABLE_SESSION_KEYS</code> metadata 参数</li><li>增加<code>camera3_stream_configuration.session_parameters</code>, 保存<code>ANDROID_REQUEST_AVAILABLE_SESSION_KEYS</code>对应的初始化值</li><li>增加 metadata 支持逻辑相机功能<ul><li>ANDROID_REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA</li><li>ANDROID_LOGICAL_MULTI_CAMERA_PHYSICAL_IDS</li><li>ANDROID_LOGICAL_MULTI_CAMERA_SYNC_TYPE</li></ul></li><li>增加<code>camera3_stream.physical_camera_id</code>，逻辑相机应用可以单独设定某个物理相机设备的流配置</li><li>增加<code>camera3_capture_request.physcam_settings</code>, 逻辑相机应用可以单独设定某个物理相机设备</li></ul><h3 id="3-6-Minor-revisions-to-support-HAL-buffer-management-APIs"><a href="#3-6-Minor-revisions-to-support-HAL-buffer-management-APIs" class="headerlink" title="3.6: Minor revisions to support HAL buffer management APIs:"></a>3.6: Minor revisions to support HAL buffer management APIs:</h3><ul><li>增加<code>ANDROID_INFO_SUPPORTED_BUFFER_MANAGEMENT_VERSION</code>，判断是否支持buffer管理</li><li>增加<code>camera3_callback_ops_t</code> 几个 callback， 3.6 以下未定义，必须置空。<ul><li><code>request_stream_buffers</code>, 异步callback，向 camera service 申请 output buffer</li><li><code>return_stream_buffers</code>, 异步callback，返回给 camera service 填好的 output buffer</li><li><code>signal_stream_flush</code>, camera service 通知 HAL 即将调用 <code>configure_streams</code>, HAL 需要立即完成所有 request 并返回所有 buffers，超时则 camera service 会触发fatal error；如果 HAL 已经返回所有 buffer，则该调用被忽略</li><li><code>is_reconfiguration_required</code>, 根据新的session 参数，判断是否要重新配置流</li></ul></li><li>增加<code>CAMERA3_JPEG_APP_SEGMENTS_BLOB_ID</code></li></ul><h2 id="Camera-HAL-启动和调用流程"><a href="#Camera-HAL-启动和调用流程" class="headerlink" title="Camera HAL 启动和调用流程"></a>Camera HAL 启动和调用流程</h2><ol><li><p>Framework 调用<code>camera_module_t-&gt;common.open()</code>, 返回<code>hardware_device_t</code>结构.</p></li><li><p>Framework 根据<code>hardware_device_t-&gt;version</code>的值，把返回的对象实例转换成对应版本的 device handler； 比如 <code>CAMERA_DEVICE_API_VERSION_3_0</code>则转换成<code>camera3_device_t</code></p></li><li><p>Framework 调用<code>camera3_device_t-&gt;ops-&gt;initialize</code>, 必须是在<code>open</code>之后其它功能函数调用之前；如果不需要可以置空。</p></li><li><p>Framework 调用<code>camera3_device_t-&gt;ops-&gt;configure_streams</code>, input&#x2F;output stream参数传递给 HAL</p></li><li><p>注册输出流</p><ul><li><code>CAMERA_DEVICE_API_VERSION_3_1</code>及以下版本，Framework 分配好 gralloc buffer，并调用<code>camera3_device_t-&gt;ops-&gt;register_stream_buffers</code>，注册输出流，每个流仅需注册一次</li><li><code>CAMERA_DEVICE_API_VERSION_3_2</code>及以上版本，<code>camera3_device_t-&gt;ops-&gt;register_stream_buffers</code>置空</li></ul></li><li><p>Framework 调用<code>camera3_device_t-&gt;ops-&gt;construct_default_request_settings</code>，获取特定 usecase 的默认设置， 可以在 step3 之后的任意时刻调用</p></li><li><p>Framework 基于获取的 usecase 默认设置，调用<code>camera3_device_t-&gt;ops-&gt;process_capture_request</code>发起第一个 capture request 到 HAL，至少有一个已注册的输出流，这是一个同步调用，HAL 会block 住直到可以处理下一个 request 才返回</p><ul><li><code>CAMERA_DEVICE_API_VERSION_3_2</code>及以上，request 带下来的<code>buffer_handle_t</code>必须是全新的对象</li></ul></li><li><p>Framework 继续发起 request</p><ul><li>需要的话调用<code>construct_default_request_settings</code>获取 usecase 默认设置</li><li>3.1 及以下，对于尚未注册的输出流，需要调用<code>register_stream_buffers</code>注册</li></ul></li><li><p>拍照动作开始，Sensor 开始曝光</p><ul><li>3.2 及以上，HAL 调用<code>camera3_callback_ops_t-&gt;notify</code> 通知上层 <strong>SHUTTER event</strong>, 包括 <code>frame number</code> 和 <code>timestamp</code>; 因为 framework 必须要有 timestamp 才能 deliver gralloc buffer 给应用，所以 <code>notify</code> 必须尽可能早</li><li>3.1 及以下，必须在调用<code>process_capture_result</code>之前调用<code>notify</code></li><li><strong>partial metadata results</strong> 和 <strong>gralloc buffer</strong> 可以在 <strong>SHUTTER event</strong> 前或者后发送给 Framework</li></ul></li><li><p>pipeline 处理需要时间，pipeline 处理完，HAL 调用<code>camera3_callback_ops_t-&gt;process_capture_result</code>通知 Framework 返回结果。顺序与发起 request 的顺序一一对应。</p><ul><li>3.2 及以上，返回之前，buffer 对应的<code>release_fence</code>会被调用，所有权移交给 Framework</li><li>HAL 可以调用多次<code>process_capture_result</code> 更新 <strong>partial metadata results</strong>, Framework 负责合成最终的结果</li><li>特别地，对于第 N 帧和第 N+1 帧，该回调可以被同时调到</li></ul></li><li><p>一段时间之后，Framework 停止发送 request，并等待所有 capture 处理完成。然后又调用 <code>configure_streams</code>, 这会重置相机硬件和 pipeline，重新配置输入输出流，流可以被复用，并且已注册过的输出流不需要再注册。如果至少有一个注册流，则重复 step7 开始的过程。如果没有注册流，则重复 step5 之后的过程。</p></li><li><p>Framework 调用 <code>camera3_device_t-&gt;common-&gt;close()</code> 关闭相机设备，该调用是同步调用过程，需要等待所有输出返回。close 返回之后，HAL 不再允许调用 <code>camera3_callback_ops_t</code> 的任何方法</p></li><li><p>当错误发生,或者有异步事件时, HAL 调用 <code>camera3_callback_ops_t-&gt;notify()</code> 通知 Framework。当发生 <strong>fatal error</strong> 之后，HAL 应该按照 <strong>close</strong> 类似的处理流程，取消或强制执行完所有任务之后再调用 <code>notify</code>, 确保 Framework 在此期间不会收到任何回调。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Android Camera HAL 作为 Framework 层 Camera2 API 接口与底层硬件实现的桥梁，起着承上启下的作用。另外从 &lt;code&gt;Android 8.0&lt;/code&gt; 开始使用了新的 &lt;code&gt;Treble&lt;/code&gt; 架构（HAL 接口与实现代码在 &lt;code&gt;hardware/interfaces/camera/&lt;/code&gt;），舍弃了原本旧的架构实现（Legacy HAL: &lt;code&gt;hardware/libhardware/modules/camera/&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;Legacy HAL 当前还保留的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hardware/libhardware/include/hardware/camera*.h&lt;/code&gt;, Camera Hal 接口定义，持续更新&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hardware/libhardware/modules/camera/3_0/&lt;/code&gt;, &lt;code&gt;camera.default&lt;/code&gt; Legacy 默认实现&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hardware/libhardware/modules/camera/3_4/&lt;/code&gt;, &lt;code&gt;camera.v4l2&lt;/code&gt; 非官方实现（树莓派）0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;截止目前最新版本是 HALv3，高端机型基本上都支持。Camera HAL 属于相对比较复杂的一个硬件模块，随着硬件模组的发展，HAL 接口也在不断变化 v1, v2 对应 &lt;code&gt;android.hardware.Camera&lt;/code&gt; API, 已经不再被支持。&lt;/p&gt;
&lt;p&gt;熟悉了 &lt;a href=&quot;/2020/10/22/Android-HAL-Intro/&quot; title=&quot;Android HAL 介绍&quot;&gt;Android HAL 介绍&lt;/a&gt; ，再来看 Camera HAL 会更容易理解。&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
  <entry>
    <title>Android HAL 介绍</title>
    <link href="https://waterdropw.github.io/2020/10/22/Android-HAL-Intro/"/>
    <id>https://waterdropw.github.io/2020/10/22/Android-HAL-Intro/</id>
    <published>2020-10-22T02:48:12.000Z</published>
    <updated>2025-11-20T11:52:31.170Z</updated>
    
    <content type="html"><![CDATA[<p>一个硬件设备对应一个模块（动态库），可以各自独立更新，模块版本与设备版本需要保持兼容性，也就是特定版本的模块，只能加载与之兼容的设备。通常情况模块具有向后兼容性，支持最高版本及其以下版本的设备。</p><p>模块封装了该类型设备的通用操作，接口很少发生变动或者只是增加新接口，确保二进制兼容性，兼容低版本设备。</p><p>设备封装了特定版本的硬件设备，接口变化更频繁，类似 <strong>camera</strong> 从 <code>HALv1</code>, <code>HALv2</code> 到目前的 <code>HALv3</code>，封装成不同的设备子类，具体硬件根据其硬件特性选择实现不同版本的 device 接口。</p><span id="more"></span><p><code>hw_device_t</code> 作为 device 的基类，放置于继承的具体设备类型 <code>struct</code> 子类的第一个位置，好处是首地址相同，可以直接做类型转换。子类型需要实现对应版本的接口函数，<br><code>hw_module_t</code> 作为 module 的基类，放置于继承的具体模块类型 <code>struct</code> 子类的第一个位置，好处是首地址相同，可以直接做类型转换。基类定义了唯一一个接口函数。</p><p><code>hw_module_methods_t.open</code>, 打开硬件设备。所有模块都需要实现该接口。不同类型的模块可以定义自己的接口函数，比如 <code>camera</code>, <code>gralloc</code>, <code>hwcomposer</code> 等等</p><h2 id="模块加载"><a href="#模块加载" class="headerlink" title="模块加载"></a>模块加载</h2><p>指定模块名称 <strong>MODULE_ID</strong>，加载时根据模块名称查找对应的动态库并加载，获取模块结构体对象地址，调用 <strong>open device</strong> 打开硬件设备，即可使用设备提供的功能。</p><p>路径查找，先根据 variant 确定动态库后缀名称，<code>&lt;MODULE_ID&gt;.variant.so</code>，按优先级依次是：</p><ol><li><strong>ro.hardware</strong></li><li><strong>ro.product.board</strong></li><li><strong>ro.board.platform</strong></li><li><strong>ro.arch</strong></li></ol><p>完整名称确定后，按照如下优先级查找对应路径：</p><ol><li><strong>&#x2F;odm&#x2F;lib64&#x2F;hw</strong></li><li><strong>&#x2F;vendor&#x2F;lib64&#x2F;hw</strong></li><li><strong>&#x2F;system&#x2F;lib64&#x2F;hw</strong></li></ol><p>所有模块的 <code>hw_module_t.hal_api_version</code> 字段必须填入 <code>HARDWARE_HAL_API_VERSION</code>，该值目前取值是 <strong>1.0</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; libhardware/include/hardware/hardware.h</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The current HAL API version.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * All module implementations must set the hw_module_t.hal_api_version field</span></span><br><span class="line"><span class="comment"> * to this value when declaring the module with HAL_MODULE_INFO_SYM.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Note that previous implementations have always set this field to 0.</span></span><br><span class="line"><span class="comment"> * Therefore, libhardware HAL API will always consider versions 0.0 and 1.0</span></span><br><span class="line"><span class="comment"> * to be 100% binary compatible.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HARDWARE_HAL_API_VERSION HARDWARE_MAKE_API_VERSION(1, 0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Name of the hal_module_info</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_MODULE_INFO_SYM         HMI</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Name of the hal_module_info as a string</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_MODULE_INFO_SYM_AS_STR  <span class="string">&quot;HMI&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get the module info associated with a module by id.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @return: 0 == success, &lt;0 == error and *module == NULL</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">hw_get_module</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *id, <span class="type">const</span> <span class="keyword">struct</span> <span class="type">hw_module_t</span> **<span class="keyword">module</span>)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; hardware/libhardware/hardware.c</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Base path of the hal modules */</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(__LP64__)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH1 <span class="string">&quot;/system/lib64/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH2 <span class="string">&quot;/vendor/lib64/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH3 <span class="string">&quot;/odm/lib64/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH1 <span class="string">&quot;/system/lib/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH2 <span class="string">&quot;/vendor/lib/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HAL_LIBRARY_PATH3 <span class="string">&quot;/odm/lib/hw&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *variant_keys[] = &#123;</span><br><span class="line">    <span class="string">&quot;ro.hardware&quot;</span>,  <span class="comment">/* This goes first so that it can pick up a different</span></span><br><span class="line"><span class="comment">                       file on the emulator. */</span></span><br><span class="line">    <span class="string">&quot;ro.product.board&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ro.board.platform&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ro.arch&quot;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Load the file defined by the variant and if successful</span></span><br><span class="line"><span class="comment"> * return the dlopen handle and the hmi.</span></span><br><span class="line"><span class="comment"> * @return 0 = success, !0 = failure.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">load</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *id,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">char</span> *path,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="keyword">struct</span> <span class="type">hw_module_t</span> **pHmi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> status = -EINVAL;</span><br><span class="line">    <span class="type">void</span> *handle = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">hw_module_t</span> *hmi = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    handle = <span class="built_in">dlopen</span>(path, RTLD_NOW);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Get the address of the struct hal_module_info. */</span></span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *sym = HAL_MODULE_INFO_SYM_AS_STR;</span><br><span class="line">    hmi = (<span class="keyword">struct</span> <span class="type">hw_module_t</span> *)<span class="built_in">dlsym</span>(handle, sym);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Check that the id matches */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">strcmp</span>(id, hmi-&gt;id) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">ALOGE</span>(<span class="string">&quot;load: id=%s != hmi-&gt;id=%s&quot;</span>, id, hmi-&gt;id);</span><br><span class="line">        status = -EINVAL;</span><br><span class="line">        <span class="keyword">goto</span> done;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hmi-&gt;dso = handle;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* success */</span></span><br><span class="line">    status = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    *pHmi = hmi;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>举个示例，gralloc 的默认实现。</p><ol><li>首先定义模块名称 MODULE_ID 是 “gralloc”，需要写入对应的 <code>hw_module_t.id</code> 字段，加载模块时会判断是否匹配。则对应动态库是 “gralloc.variant.so”, variant 会在加载时搜索确定。</li><li>其次是定义全局可见，并且名称固定为 <code>HAL_MODULE_INFO_SYM</code> 的结构体变量，模块加载时透过 <code>dlsym</code> 搜索该变量，获取到结构体对象地址。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; libhardware/include/hardware/gralloc.h</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The id of this module</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GRALLOC_HARDWARE_MODULE_ID <span class="string">&quot;gralloc&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; libhardware/modules/gralloc/gralloc.cpp</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">hw_module_methods_t</span> gralloc_module_methods = &#123;</span><br><span class="line">        .open = gralloc_device_open</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">private_module_t</span> HAL_MODULE_INFO_SYM = &#123;</span><br><span class="line">    .base = &#123;</span><br><span class="line">        .common = &#123;</span><br><span class="line">            .tag = HARDWARE_MODULE_TAG,</span><br><span class="line">            .version_major = <span class="number">1</span>,</span><br><span class="line">            .version_minor = <span class="number">0</span>,</span><br><span class="line">            .id = GRALLOC_HARDWARE_MODULE_ID,</span><br><span class="line">            .name = <span class="string">&quot;Graphics Memory Allocator Module&quot;</span>,</span><br><span class="line">            .author = <span class="string">&quot;The Android Open Source Project&quot;</span>,</span><br><span class="line">            .methods = &amp;gralloc_module_methods</span><br><span class="line">        &#125;,</span><br><span class="line">        .registerBuffer = gralloc_register_buffer,</span><br><span class="line">        .unregisterBuffer = gralloc_unregister_buffer,</span><br><span class="line">        .lock = gralloc_lock,</span><br><span class="line">        .unlock = gralloc_unlock,</span><br><span class="line">    &#125;,</span><br><span class="line">    .framebuffer = <span class="number">0</span>,</span><br><span class="line">    .flags = <span class="number">0</span>,</span><br><span class="line">    .numBuffers = <span class="number">0</span>,</span><br><span class="line">    .bufferMask = <span class="number">0</span>,</span><br><span class="line">    .lock = PTHREAD_MUTEX_INITIALIZER,</span><br><span class="line">    .currentBuffer = <span class="number">0</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Every hardware module must have a data structure named HAL_MODULE_INFO_SYM</span></span><br><span class="line"><span class="comment"> * and the fields of this data structure must begin with hw_module_t</span></span><br><span class="line"><span class="comment"> * followed by module specific information.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">gralloc_module_t</span> &#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">hw_module_t</span> common;</span><br><span class="line">    ...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>gralloc.default.so</code> 符号表，可以看到有 <strong>HMI</strong> 符号，获取到的就是 <code>private_module_t</code>结构体对象地址</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Symbol table <span class="string">&#x27;.dynsym&#x27;</span> contains <span class="number">33</span> entries:</span><br><span class="line">   Num:    Value          Size Type    Bind   Vis      Ndx Name</span><br><span class="line">     <span class="number">0</span>: <span class="number">0000000000000000</span>     <span class="number">0</span> NOTYPE  LOCAL  DEFAULT  UND</span><br><span class="line">    <span class="number">24</span>: <span class="number">0000000000002</span>a18   <span class="number">332</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z14fb_device_openPK11hw_</span><br><span class="line">    <span class="number">25</span>: <span class="number">0000000000002e94</span>   <span class="number">200</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z25gralloc_unregister_bu</span><br><span class="line">    <span class="number">26</span>: <span class="number">0000000000004010</span>   <span class="number">688</span> OBJECT  GLOBAL DEFAULT   <span class="number">15</span> HMI</span><br><span class="line">    <span class="number">27</span>: <span class="number">0000000000003060</span>   <span class="number">124</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z12gralloc_lockPK16grall</span><br><span class="line">    <span class="number">28</span>: <span class="number">00000000000030</span>dc   <span class="number">116</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z14gralloc_unlockPK16gra</span><br><span class="line">    <span class="number">29</span>: <span class="number">0000000000002f</span>f8   <span class="number">104</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z15terminateBufferPK16gr</span><br><span class="line">    <span class="number">30</span>: <span class="number">0000000000002504</span>  <span class="number">1132</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z20mapFrameBufferLockedP</span><br><span class="line">    <span class="number">31</span>: <span class="number">0000000000002</span>d68   <span class="number">300</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z23gralloc_register_buff</span><br><span class="line">    <span class="number">32</span>: <span class="number">0000000000002f</span>5c   <span class="number">156</span> FUNC    GLOBAL DEFAULT   <span class="number">13</span> _Z9mapBufferPK16gralloc_m</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;一个硬件设备对应一个模块（动态库），可以各自独立更新，模块版本与设备版本需要保持兼容性，也就是特定版本的模块，只能加载与之兼容的设备。通常情况模块具有向后兼容性，支持最高版本及其以下版本的设备。&lt;/p&gt;
&lt;p&gt;模块封装了该类型设备的通用操作，接口很少发生变动或者只是增加新接口，确保二进制兼容性，兼容低版本设备。&lt;/p&gt;
&lt;p&gt;设备封装了特定版本的硬件设备，接口变化更频繁，类似 &lt;strong&gt;camera&lt;/strong&gt; 从 &lt;code&gt;HALv1&lt;/code&gt;, &lt;code&gt;HALv2&lt;/code&gt; 到目前的 &lt;code&gt;HALv3&lt;/code&gt;，封装成不同的设备子类，具体硬件根据其硬件特性选择实现不同版本的 device 接口。&lt;/p&gt;</summary>
    
    
    
    <category term="Android" scheme="https://waterdropw.github.io/categories/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/categories/Android/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/categories/Android/Camera/HAL/"/>
    
    
    <category term="Android" scheme="https://waterdropw.github.io/tags/Android/"/>
    
    <category term="Camera" scheme="https://waterdropw.github.io/tags/Camera/"/>
    
    <category term="HAL" scheme="https://waterdropw.github.io/tags/HAL/"/>
    
  </entry>
  
</feed>
